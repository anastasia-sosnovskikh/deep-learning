{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cc6d4e",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "PyTorch is a deep learning framework developed by Facebook's AI Research Group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319072cf",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e111c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d50599",
   "metadata": {},
   "source": [
    "### zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f55ce64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.zeros(4,3)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc0c230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b653410",
   "metadata": {},
   "source": [
    "### randn() and randn_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b39f9a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1878,  0.6123,  0.5717],\n",
       "        [-1.6159, -0.6082,  0.5684],\n",
       "        [ 1.1030, -0.1915, -0.3217],\n",
       "        [-1.6151,  0.4028,  1.4529]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor from a normal distribution (mean=0, std=1)\n",
    "w = torch.randn(4,3) \n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab0dbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8912,  0.8942, -0.5595],\n",
       "        [ 0.6670, -0.2391,  1.1755],\n",
       "        [-0.3609,  0.0833,  1.0462],\n",
       "        [-0.5692,  1.6452,  0.0912]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor from a normal distribution with the size of another tensor\n",
    "t = torch.randn_like(w)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af32fc2",
   "metadata": {},
   "source": [
    "### fill()\n",
    "\n",
    "Functions with `_` at the end are in-place functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b8714bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.fill_(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5eddf",
   "metadata": {},
   "source": [
    "### view()\n",
    "Reshaping a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e783469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3690d90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = w.view(3,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02a566ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.view(3,-1) # the second dimention is left for the function to figure out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a0d14",
   "metadata": {},
   "source": [
    "### numpy\n",
    "Convert from tensor to numpy array\n",
    "If torch tensor is on CPU, then they will share the locations which would mean that changing one would change the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9e0fb99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d6c8c",
   "metadata": {},
   "source": [
    "## Loss  (Criterion)\n",
    "Takes in what the model predicts and correct label and computes how far the prediction is.\n",
    "Loss function for problem types:\n",
    "\n",
    "| problem type | last-layer activation | loss function |\n",
    "| :---: | :---: | :---: |\n",
    "| binary classification | sigmoid | binary crossentropy |\n",
    "| multiclass, single label classification | softmax | categorical crossentropy |\n",
    "| multiclass, multilabel classification | sigmoid | binary crossentropy |\n",
    "| regression to arbitrary values | none | MSE |\n",
    "| regression to values between 0 and 1 | sigmoid | MSE or binary crossentropy |\n",
    "\n",
    "Adjusting weights to minimize the loss using Gradient Descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f47980",
   "metadata": {},
   "source": [
    "## EXAMPLE: Fashion MNIST and NNs\n",
    "\n",
    "* 70000 images (60000 for training and 10000 for testing)\n",
    "* 28 x 28 pixels\n",
    "* 10 categories (levels 0 - 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45b4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds ensure we have the same results - this is not guaranteed across PyTorch releases though\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1fc384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996acb4ad98c49589e3f57575a5dbdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6faef5d67249bba6caddca30fbb69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8dd3144b61492a85861ea2b28404b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c2e3b569ee4fdea27615dfaee32411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\anast/.pytorch/FMNIST/FashionMNIST\\raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anast\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load TRAINING data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load TEST data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c876299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  `FMNIST` class from inhereting attributes and methods from a superclass\n",
    "# `FMNIST` is a derived or a subclass of `nn.Module`\n",
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    #Inititalize the data with `__init__()` that specifies how to initialize the data  \n",
    "    #Object is passed to the first argument `self`\n",
    "    super().__init__() \n",
    "    self.fc1 = nn.Linear(784, 128) # 784 -> 128\n",
    "    self.fc2 = nn.Linear(128,64) # 128 -> 64\n",
    "    self.fc3 = nn.Linear(64,10) # 64 -> 10\n",
    "\n",
    "\n",
    "#`forward` defines the order of different layers of NN\n",
    "#`F` has the functions implemented\n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    #Declare the layers\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1) # loss function\n",
    "    \n",
    "    return x\n",
    "\n",
    "model = FMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bdaa91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0338174501843036\n",
      "Training loss: 0.5608082033360182\n",
      "Training loss: 0.4914347628699437\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "# Steps:\n",
    "# 1. take a batch of images and targets\n",
    "# 2. forward pass - run them through NN\n",
    "# 3. calculate loss of NN on batch by measuring the mismatch \n",
    "# 4. update the weights of NN\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss() # defnining loss function \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3 # can increase it but be aware of overfitting and time requirements\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0 # track of loss for each batch\n",
    "\n",
    "    for images, labels in trainloader: # 1. take a batch\n",
    "        optimizer.zero_grad() # zero out gradients\n",
    "        output = model(images) # 2. forward pass\n",
    "        loss = criterion(output, labels) # 3. calculate loss\n",
    "        loss.backward() \n",
    "        optimizer.step() # update the weights\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "     \n",
    "    print(f\"Training loss: {cum_loss/len(trainloader)}\") # print at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0076c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "test_image_id = 13\n",
    "img = images[test_image_id].view(1, 784) \n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf3b631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = torch.exp(logps)\n",
    "nps = ps.numpy()[0]\n",
    "FMNIST_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sport Shoes','Bag','Ankle Boot']\n",
    "plt.xticks(np.arange(10),labels=FMNIST_labels,rotation='vertical')\n",
    "plt.bar(np.arange(10), nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c39e7bc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-ae00458c8f5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdenormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "def denormalize(tensor):\n",
    "  tensor = tensor*0.5 + 0.5\n",
    "  return tensor\n",
    "  \n",
    "img = img.view(28,-1)\n",
    "img = denormalize(img)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1089a",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "Used to automatically calculate the gradients of tensors.\n",
    "Forward pass: calculate the loss\n",
    "Backward pass: calculate the gradient of the loss with respect to each of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e20397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73596717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc62b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 128)\n",
    "    self.fc2 = nn.Linear(128,64)\n",
    "    self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "#model = FMNIST()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edd1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to define the network to be able to see the weights (class defining method does not support this)\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac1bb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20eb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e0a85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab857258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights : Parameter containing:\n",
      "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
      "        [-0.0233, -0.0220, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
      "        [ 0.0309,  0.0066,  0.0125,  ...,  0.0286,  0.0350, -0.0105]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# forward pass is done, weights are calculated\n",
    "print('Initial Weights :', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da64ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights gradients : None\n"
     ]
    }
   ],
   "source": [
    "# have not done the backwards pass yet, so there should be no gradients\n",
    "print('Initial Weights gradients :', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f49fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights :  Parameter containing:\n",
      "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
      "        [-0.0233, -0.0220, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
      "        [ 0.0309,  0.0066,  0.0125,  ...,  0.0286,  0.0350, -0.0105]],\n",
      "       requires_grad=True)\n",
      "Initial weights gradient :  tensor([[-7.2154e-04, -7.2154e-04, -7.2154e-04,  ..., -7.1856e-04,\n",
      "         -7.2154e-04, -7.2154e-04],\n",
      "        [ 1.5117e-03,  1.5168e-03,  1.5292e-03,  ...,  1.5526e-03,\n",
      "          1.5154e-03,  1.5168e-03],\n",
      "        [-4.5585e-04, -4.5585e-04, -4.5585e-04,  ..., -4.5585e-04,\n",
      "         -4.5585e-04, -4.5585e-04],\n",
      "        ...,\n",
      "        [-9.6583e-05, -9.6583e-05, -9.6583e-05,  ..., -1.5217e-04,\n",
      "         -9.6583e-05, -9.6583e-05],\n",
      "        [-5.6446e-04, -5.6559e-04, -5.5394e-04,  ..., -5.1035e-04,\n",
      "         -5.6446e-04, -5.6559e-04],\n",
      "        [ 3.7556e-03,  3.7518e-03,  3.7486e-03,  ...,  3.7677e-03,\n",
      "          3.7556e-03,  3.7518e-03]])\n"
     ]
    }
   ],
   "source": [
    "# forwads pass, calculate the loss, and then do a backward pass\n",
    "# weights are the same, gradients are calculated by autograd\n",
    "# activation function does not have any weights, it's role is to add non-linearity to NN\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Initial weights : ',model[0].weight)\n",
    "print('Initial weights gradient : ',model[0].weight.grad)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e079c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0825, -0.0339,  0.0713,  ..., -0.0854,  0.0097, -0.0645],\n",
       "        [ 0.0488,  0.0832,  0.0728,  ..., -0.0440,  0.0541,  0.0612],\n",
       "        [-0.0055, -0.0093, -0.0157,  ...,  0.0782,  0.0032, -0.0530],\n",
       "        ...,\n",
       "        [ 0.0009,  0.0023, -0.0776,  ...,  0.0575,  0.0759,  0.0016],\n",
       "        [-0.0815, -0.0214, -0.0414,  ...,  0.0702, -0.0252,  0.0703],\n",
       "        [-0.0815,  0.0329, -0.0134,  ...,  0.0773,  0.0774,  0.0468]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d94f01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9982e-04,  7.5449e-04, -3.4903e-04,  ..., -4.0108e-03,\n",
       "         -4.7830e-04,  1.6829e-03],\n",
       "        [-3.7763e-03, -7.4046e-03, -1.6994e-03,  ...,  4.3599e-03,\n",
       "         -2.2660e-03, -6.2232e-03],\n",
       "        [ 0.0000e+00,  3.7159e-04,  2.0443e-05,  ..., -7.8269e-05,\n",
       "          0.0000e+00, -1.6872e-04],\n",
       "        ...,\n",
       "        [ 1.0783e-04,  5.2203e-03,  1.4267e-03,  ...,  5.2378e-04,\n",
       "         -1.5976e-03, -1.1809e-03],\n",
       "        [ 2.2829e-03,  5.4146e-03,  4.5451e-04,  ..., -1.0207e-02,\n",
       "         -2.3595e-03,  2.7769e-03],\n",
       "        [-3.4852e-03, -5.0445e-03, -1.5482e-03,  ...,  1.0569e-02,\n",
       "          2.0605e-03, -3.6040e-03]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753f810",
   "metadata": {},
   "source": [
    "## Autograd with Tensors\n",
    "Again, autotograd used for automatically calculating the gradients of tensors.\n",
    "It works by keeping track of operations performed on tensors, and then goes back and calculates gradients on them.\n",
    "You need to set `requires_grad=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9e28a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(4,3,requires_grad=True)\n",
    "# can also set it after the tensor is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "241e0fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8374, 4.4017, 0.0434],\n",
       "        [2.6044, 1.4517, 2.3675],\n",
       "        [6.8272, 1.0815, 0.8180],\n",
       "        [0.8387, 0.4668, 0.4391]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.exp(w)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7081eedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ExpBackward at 0x21cd9249a30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autograd module keeps track of the operations\n",
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64e3b678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8481, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp = y.mean()\n",
    "outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1419419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# haven't run the backward funciton yet, so gradients are not calculated yet\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c4aac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the gradients of `outp` with respect to `w`\n",
    "outp.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5abddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0698, 0.3668, 0.0036],\n",
       "        [0.2170, 0.1210, 0.1973],\n",
       "        [0.5689, 0.0901, 0.0682],\n",
       "        [0.0699, 0.0389, 0.0366]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ed02f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1774,  1.4820, -3.1377],\n",
       "        [ 0.9572,  0.3727,  0.8618],\n",
       "        [ 1.9209,  0.0783, -0.2009],\n",
       "        [-0.1760, -0.7618, -0.8230]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the method `detach()` to detach from computation history\n",
    "w.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32d9ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# if you don't need gradients to be calculated\n",
    "print(outp.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outp = (w+y).mean()\n",
    "    \n",
    "print(outp.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b1bde",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "Determine how the network weights will be updated based on the loss function.\n",
    "In other words, optimizer uses loss function to update the weights by implementing a variant of Stochastic Gradient Descent.\n",
    "\n",
    "Training steps:\n",
    "* take a batch of samples and targets\n",
    "* forward pass\n",
    "* calculating loss (the difference between the predicted values and the target)\n",
    "* backward pass (compute the gradient of the loss with regard to the network's parameters)\n",
    "* reduce the loss by taking the step of the optimizer by taking the previous step of the parameter, subtracting the learning rate multiplied by the gradient of loss\n",
    "\n",
    "Important to remember to **zero out the gradients for each epoch** with `optimizer.zero_grad()` because they are relevant for a particular batch of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c252948",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCdIqY0tKbvS"
   },
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58ef8c11",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCJzXv0OK1Bs"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb071ddb",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqMqFbIVrbFH"
   },
   "outputs": [],
   "source": [
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 128)\n",
    "    self.fc2 = nn.Linear(128,64)\n",
    "    self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "#model = FMNIST()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6c3b55d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8c0QgxCF3fD-"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43aac69b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iPQek2nz2yu"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6c76c70",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roihp-kN0Jw5"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) # lr = learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c0e7b97",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Nf2WdmP5Gst"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights :  Parameter containing:\n",
      "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
      "        [-0.0233, -0.0220, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
      "        [ 0.0309,  0.0066,  0.0125,  ...,  0.0286,  0.0350, -0.0105]],\n",
      "       requires_grad=True)\n",
      "Initial weights gradient :  tensor([[-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "        [ 0.0045,  0.0046,  0.0046,  ...,  0.0047,  0.0045,  0.0046],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        ...,\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0005, -0.0003, -0.0003],\n",
      "        [-0.0017, -0.0017, -0.0017,  ..., -0.0015, -0.0017, -0.0017],\n",
      "        [ 0.0113,  0.0113,  0.0112,  ...,  0.0113,  0.0113,  0.0113]])\n"
     ]
    }
   ],
   "source": [
    "output = model(images) # forward pass\n",
    "loss = criterion(output, labels) # calculate loss\n",
    "loss.backward() # backward pass\n",
    "print('Initial weights : ',model[0].weight)\n",
    "print('Initial weights gradient : ',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff07cc3c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "arwzAK-1EkEH"
   },
   "outputs": [],
   "source": [
    "# update the weights using the step function of the optimizer\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df690c22",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuGKi_nq6P0j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights :  Parameter containing:\n",
      "tensor([[-0.0002,  0.0192, -0.0294,  ...,  0.0220,  0.0038,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
      "        [-0.0232, -0.0220, -0.0064,  ...,  0.0115, -0.0323, -0.0158],\n",
      "        [ 0.0308,  0.0065,  0.0124,  ...,  0.0284,  0.0349, -0.0106]],\n",
      "       requires_grad=True)\n",
      "Initial weights gradient :  tensor([[-0.0022, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0022],\n",
      "        [ 0.0045,  0.0046,  0.0046,  ...,  0.0047,  0.0045,  0.0046],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        ...,\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0005, -0.0003, -0.0003],\n",
      "        [-0.0017, -0.0017, -0.0017,  ..., -0.0015, -0.0017, -0.0017],\n",
      "        [ 0.0113,  0.0113,  0.0112,  ...,  0.0113,  0.0113,  0.0113]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights : ',model[0].weight)\n",
    "print('Initial weights gradient : ',model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8aa0bf0d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnfpzGigEpAr"
   },
   "outputs": [],
   "source": [
    "# do not want to accumulate the gradients - MUST zero them out\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f580e286",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EniqxHDwDa8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights :  Parameter containing:\n",
      "tensor([[-0.0002,  0.0192, -0.0294,  ...,  0.0220,  0.0038,  0.0021],\n",
      "        [-0.0198, -0.0150, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n",
      "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
      "        [-0.0232, -0.0220, -0.0064,  ...,  0.0115, -0.0323, -0.0158],\n",
      "        [ 0.0308,  0.0065,  0.0124,  ...,  0.0284,  0.0349, -0.0106]],\n",
      "       requires_grad=True)\n",
      "Initial weights gradient :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights : ',model[0].weight) \n",
    "print('Initial weights gradient : ',model[0].weight.grad) # zeroed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95fad540",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGZhQE3tDcqb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 1, Loss: 2.288628578186035\n",
      "Batch : 2, Loss: 2.3080620765686035\n",
      "Batch : 3, Loss: 2.3098013401031494\n",
      "Batch : 4, Loss: 2.284043312072754\n",
      "Batch : 5, Loss: 2.291738986968994\n",
      "Batch : 6, Loss: 2.3061680793762207\n",
      "Batch : 7, Loss: 2.2870423793792725\n",
      "Batch : 8, Loss: 2.276984453201294\n",
      "Batch : 9, Loss: 2.2776780128479004\n",
      "Batch : 10, Loss: 2.3024075031280518\n",
      "Batch : 11, Loss: 2.270155906677246\n",
      "Batch : 12, Loss: 2.288559913635254\n",
      "Batch : 13, Loss: 2.2820968627929688\n",
      "Batch : 14, Loss: 2.2649171352386475\n",
      "Batch : 15, Loss: 2.274873971939087\n",
      "Batch : 16, Loss: 2.2665631771087646\n",
      "Batch : 17, Loss: 2.2486894130706787\n",
      "Batch : 18, Loss: 2.25093150138855\n",
      "Batch : 19, Loss: 2.2826104164123535\n",
      "Batch : 20, Loss: 2.2532405853271484\n",
      "Batch : 21, Loss: 2.234309434890747\n",
      "Batch : 22, Loss: 2.259300470352173\n",
      "Batch : 23, Loss: 2.248821496963501\n",
      "Batch : 24, Loss: 2.2512760162353516\n",
      "Batch : 25, Loss: 2.2572567462921143\n",
      "Batch : 26, Loss: 2.2401793003082275\n",
      "Batch : 27, Loss: 2.214656352996826\n",
      "Batch : 28, Loss: 2.226203441619873\n",
      "Batch : 29, Loss: 2.2151873111724854\n",
      "Batch : 30, Loss: 2.2176032066345215\n",
      "Batch : 31, Loss: 2.23728084564209\n",
      "Batch : 32, Loss: 2.2319469451904297\n",
      "Batch : 33, Loss: 2.2288169860839844\n",
      "Batch : 34, Loss: 2.2359673976898193\n",
      "Batch : 35, Loss: 2.2106552124023438\n",
      "Batch : 36, Loss: 2.2009663581848145\n",
      "Batch : 37, Loss: 2.228806495666504\n",
      "Batch : 38, Loss: 2.214583396911621\n",
      "Batch : 39, Loss: 2.2042295932769775\n",
      "Batch : 40, Loss: 2.1886141300201416\n",
      "Batch : 41, Loss: 2.20263409614563\n",
      "Batch : 42, Loss: 2.199158191680908\n",
      "Batch : 43, Loss: 2.169827938079834\n",
      "Batch : 44, Loss: 2.14996075630188\n",
      "Batch : 45, Loss: 2.1614444255828857\n",
      "Batch : 46, Loss: 2.1536142826080322\n",
      "Batch : 47, Loss: 2.1791305541992188\n",
      "Batch : 48, Loss: 2.174588441848755\n",
      "Batch : 49, Loss: 2.1909241676330566\n",
      "Batch : 50, Loss: 2.167595624923706\n",
      "Batch : 51, Loss: 2.170773506164551\n",
      "Batch : 52, Loss: 2.176833391189575\n",
      "Batch : 53, Loss: 2.1565167903900146\n",
      "Batch : 54, Loss: 2.119532823562622\n",
      "Batch : 55, Loss: 2.1230432987213135\n",
      "Batch : 56, Loss: 2.1416871547698975\n",
      "Batch : 57, Loss: 2.100715398788452\n",
      "Batch : 58, Loss: 2.1146628856658936\n",
      "Batch : 59, Loss: 2.1192877292633057\n",
      "Batch : 60, Loss: 2.143620729446411\n",
      "Batch : 61, Loss: 2.120922327041626\n",
      "Batch : 62, Loss: 2.0875020027160645\n",
      "Batch : 63, Loss: 2.087580442428589\n",
      "Batch : 64, Loss: 2.104800224304199\n",
      "Batch : 65, Loss: 2.1346569061279297\n",
      "Batch : 66, Loss: 2.105095624923706\n",
      "Batch : 67, Loss: 2.0743091106414795\n",
      "Batch : 68, Loss: 2.1175568103790283\n",
      "Batch : 69, Loss: 2.0749971866607666\n",
      "Batch : 70, Loss: 2.0403952598571777\n",
      "Batch : 71, Loss: 2.0589354038238525\n",
      "Batch : 72, Loss: 2.0627200603485107\n",
      "Batch : 73, Loss: 2.062371015548706\n",
      "Batch : 74, Loss: 2.0711536407470703\n",
      "Batch : 75, Loss: 2.0451242923736572\n",
      "Batch : 76, Loss: 1.9929347038269043\n",
      "Batch : 77, Loss: 2.093439817428589\n",
      "Batch : 78, Loss: 2.0415005683898926\n",
      "Batch : 79, Loss: 1.9999783039093018\n",
      "Batch : 80, Loss: 2.0731618404388428\n",
      "Batch : 81, Loss: 2.0099408626556396\n",
      "Batch : 82, Loss: 1.966227650642395\n",
      "Batch : 83, Loss: 1.9963743686676025\n",
      "Batch : 84, Loss: 1.9500380754470825\n",
      "Batch : 85, Loss: 2.032473564147949\n",
      "Batch : 86, Loss: 2.0362255573272705\n",
      "Batch : 87, Loss: 1.9684059619903564\n",
      "Batch : 88, Loss: 1.947343111038208\n",
      "Batch : 89, Loss: 2.020293951034546\n",
      "Batch : 90, Loss: 1.9370741844177246\n",
      "Batch : 91, Loss: 2.0110340118408203\n",
      "Batch : 92, Loss: 1.9739344120025635\n",
      "Batch : 93, Loss: 1.9326590299606323\n",
      "Batch : 94, Loss: 1.9520376920700073\n",
      "Batch : 95, Loss: 1.9489662647247314\n",
      "Batch : 96, Loss: 1.9084887504577637\n",
      "Batch : 97, Loss: 1.970387578010559\n",
      "Batch : 98, Loss: 1.9823907613754272\n",
      "Batch : 99, Loss: 1.9808343648910522\n",
      "Batch : 100, Loss: 2.0078608989715576\n",
      "Batch : 101, Loss: 1.9658935070037842\n",
      "Batch : 102, Loss: 1.9703658819198608\n",
      "Batch : 103, Loss: 1.9045119285583496\n",
      "Batch : 104, Loss: 1.9508436918258667\n",
      "Batch : 105, Loss: 1.9133564233779907\n",
      "Batch : 106, Loss: 1.8932511806488037\n",
      "Batch : 107, Loss: 1.8733527660369873\n",
      "Batch : 108, Loss: 1.8558356761932373\n",
      "Batch : 109, Loss: 1.8342623710632324\n",
      "Batch : 110, Loss: 1.8201653957366943\n",
      "Batch : 111, Loss: 1.8833751678466797\n",
      "Batch : 112, Loss: 1.8173471689224243\n",
      "Batch : 113, Loss: 1.8530887365341187\n",
      "Batch : 114, Loss: 1.765743374824524\n",
      "Batch : 115, Loss: 1.8477495908737183\n",
      "Batch : 116, Loss: 1.7109159231185913\n",
      "Batch : 117, Loss: 1.9003019332885742\n",
      "Batch : 118, Loss: 1.7871605157852173\n",
      "Batch : 119, Loss: 1.8380064964294434\n",
      "Batch : 120, Loss: 1.7534178495407104\n",
      "Batch : 121, Loss: 1.920150637626648\n",
      "Batch : 122, Loss: 1.8263047933578491\n",
      "Batch : 123, Loss: 1.7914687395095825\n",
      "Batch : 124, Loss: 1.78448486328125\n",
      "Batch : 125, Loss: 1.811231017112732\n",
      "Batch : 126, Loss: 1.7456862926483154\n",
      "Batch : 127, Loss: 1.7881054878234863\n",
      "Batch : 128, Loss: 1.7524638175964355\n",
      "Batch : 129, Loss: 1.827263355255127\n",
      "Batch : 130, Loss: 1.7048755884170532\n",
      "Batch : 131, Loss: 1.6778533458709717\n",
      "Batch : 132, Loss: 1.7147760391235352\n",
      "Batch : 133, Loss: 1.7225536108016968\n",
      "Batch : 134, Loss: 1.6499106884002686\n",
      "Batch : 135, Loss: 1.6625670194625854\n",
      "Batch : 136, Loss: 1.768476128578186\n",
      "Batch : 137, Loss: 1.7792234420776367\n",
      "Batch : 138, Loss: 1.6747989654541016\n",
      "Batch : 139, Loss: 1.6496049165725708\n",
      "Batch : 140, Loss: 1.6461516618728638\n",
      "Batch : 141, Loss: 1.7905761003494263\n",
      "Batch : 142, Loss: 1.6515014171600342\n",
      "Batch : 143, Loss: 1.6357389688491821\n",
      "Batch : 144, Loss: 1.6526902914047241\n",
      "Batch : 145, Loss: 1.6028414964675903\n",
      "Batch : 146, Loss: 1.5982884168624878\n",
      "Batch : 147, Loss: 1.661482810974121\n",
      "Batch : 148, Loss: 1.6338558197021484\n",
      "Batch : 149, Loss: 1.650547742843628\n",
      "Batch : 150, Loss: 1.6519229412078857\n",
      "Batch : 151, Loss: 1.5536859035491943\n",
      "Batch : 152, Loss: 1.6730996370315552\n",
      "Batch : 153, Loss: 1.589125156402588\n",
      "Batch : 154, Loss: 1.6246918439865112\n",
      "Batch : 155, Loss: 1.6287909746170044\n",
      "Batch : 156, Loss: 1.5493741035461426\n",
      "Batch : 157, Loss: 1.6292805671691895\n",
      "Batch : 158, Loss: 1.6461304426193237\n",
      "Batch : 159, Loss: 1.7075464725494385\n",
      "Batch : 160, Loss: 1.5601609945297241\n",
      "Batch : 161, Loss: 1.6359126567840576\n",
      "Batch : 162, Loss: 1.6543128490447998\n",
      "Batch : 163, Loss: 1.5897878408432007\n",
      "Batch : 164, Loss: 1.537859559059143\n",
      "Batch : 165, Loss: 1.5736342668533325\n",
      "Batch : 166, Loss: 1.5079853534698486\n",
      "Batch : 167, Loss: 1.4420347213745117\n",
      "Batch : 168, Loss: 1.5722801685333252\n",
      "Batch : 169, Loss: 1.603189468383789\n",
      "Batch : 170, Loss: 1.514262080192566\n",
      "Batch : 171, Loss: 1.5211890935897827\n",
      "Batch : 172, Loss: 1.453373908996582\n",
      "Batch : 173, Loss: 1.6026358604431152\n",
      "Batch : 174, Loss: 1.440950632095337\n",
      "Batch : 175, Loss: 1.4144083261489868\n",
      "Batch : 176, Loss: 1.481160044670105\n",
      "Batch : 177, Loss: 1.5983346700668335\n",
      "Batch : 178, Loss: 1.3538738489151\n",
      "Batch : 179, Loss: 1.471993088722229\n",
      "Batch : 180, Loss: 1.3759490251541138\n",
      "Batch : 181, Loss: 1.586784839630127\n",
      "Batch : 182, Loss: 1.5142019987106323\n",
      "Batch : 183, Loss: 1.4200574159622192\n",
      "Batch : 184, Loss: 1.3368011713027954\n",
      "Batch : 185, Loss: 1.4060505628585815\n",
      "Batch : 186, Loss: 1.348827600479126\n",
      "Batch : 187, Loss: 1.3889178037643433\n",
      "Batch : 188, Loss: 1.4449409246444702\n",
      "Batch : 189, Loss: 1.4007185697555542\n",
      "Batch : 190, Loss: 1.3079633712768555\n",
      "Batch : 191, Loss: 1.4353827238082886\n",
      "Batch : 192, Loss: 1.4128139019012451\n",
      "Batch : 193, Loss: 1.4986470937728882\n",
      "Batch : 194, Loss: 1.4947435855865479\n",
      "Batch : 195, Loss: 1.3934251070022583\n",
      "Batch : 196, Loss: 1.3159420490264893\n",
      "Batch : 197, Loss: 1.2503217458724976\n",
      "Batch : 198, Loss: 1.4704385995864868\n",
      "Batch : 199, Loss: 1.3396390676498413\n",
      "Batch : 200, Loss: 1.3669430017471313\n",
      "Batch : 201, Loss: 1.4082595109939575\n",
      "Batch : 202, Loss: 1.376648187637329\n",
      "Batch : 203, Loss: 1.35844087600708\n",
      "Batch : 204, Loss: 1.408490538597107\n",
      "Batch : 205, Loss: 1.359188199043274\n",
      "Batch : 206, Loss: 1.307331919670105\n",
      "Batch : 207, Loss: 1.3820321559906006\n",
      "Batch : 208, Loss: 1.3443961143493652\n",
      "Batch : 209, Loss: 1.2357741594314575\n",
      "Batch : 210, Loss: 1.3160125017166138\n",
      "Batch : 211, Loss: 1.2497817277908325\n",
      "Batch : 212, Loss: 1.4003335237503052\n",
      "Batch : 213, Loss: 1.2762998342514038\n",
      "Batch : 214, Loss: 1.3032715320587158\n",
      "Batch : 215, Loss: 1.1196099519729614\n",
      "Batch : 216, Loss: 1.3420666456222534\n",
      "Batch : 217, Loss: 1.3200669288635254\n",
      "Batch : 218, Loss: 1.4521552324295044\n",
      "Batch : 219, Loss: 1.3720651865005493\n",
      "Batch : 220, Loss: 1.2343848943710327\n",
      "Batch : 221, Loss: 1.309891939163208\n",
      "Batch : 222, Loss: 1.2885615825653076\n",
      "Batch : 223, Loss: 1.2678289413452148\n",
      "Batch : 224, Loss: 1.2900700569152832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 225, Loss: 1.212249994277954\n",
      "Batch : 226, Loss: 1.293318748474121\n",
      "Batch : 227, Loss: 1.2226338386535645\n",
      "Batch : 228, Loss: 1.2812552452087402\n",
      "Batch : 229, Loss: 1.3463066816329956\n",
      "Batch : 230, Loss: 1.2443631887435913\n",
      "Batch : 231, Loss: 1.2140558958053589\n",
      "Batch : 232, Loss: 1.3428449630737305\n",
      "Batch : 233, Loss: 1.1158798933029175\n",
      "Batch : 234, Loss: 1.20414137840271\n",
      "Batch : 235, Loss: 1.4018633365631104\n",
      "Batch : 236, Loss: 1.3054850101470947\n",
      "Batch : 237, Loss: 1.185773491859436\n",
      "Batch : 238, Loss: 1.2555246353149414\n",
      "Batch : 239, Loss: 1.1556949615478516\n",
      "Batch : 240, Loss: 1.1540135145187378\n",
      "Batch : 241, Loss: 1.1964271068572998\n",
      "Batch : 242, Loss: 1.16628098487854\n",
      "Batch : 243, Loss: 1.338180422782898\n",
      "Batch : 244, Loss: 1.0964947938919067\n",
      "Batch : 245, Loss: 1.1737427711486816\n",
      "Batch : 246, Loss: 1.282967209815979\n",
      "Batch : 247, Loss: 1.1115268468856812\n",
      "Batch : 248, Loss: 1.2255126237869263\n",
      "Batch : 249, Loss: 1.185935139656067\n",
      "Batch : 250, Loss: 1.101222038269043\n",
      "Batch : 251, Loss: 1.2300894260406494\n",
      "Batch : 252, Loss: 1.1436280012130737\n",
      "Batch : 253, Loss: 1.065886378288269\n",
      "Batch : 254, Loss: 1.0187910795211792\n",
      "Batch : 255, Loss: 1.2080402374267578\n",
      "Batch : 256, Loss: 1.1579275131225586\n",
      "Batch : 257, Loss: 1.2267752885818481\n",
      "Batch : 258, Loss: 1.1265374422073364\n",
      "Batch : 259, Loss: 1.0939688682556152\n",
      "Batch : 260, Loss: 1.1959489583969116\n",
      "Batch : 261, Loss: 1.2548528909683228\n",
      "Batch : 262, Loss: 1.1431081295013428\n",
      "Batch : 263, Loss: 1.0960959196090698\n",
      "Batch : 264, Loss: 1.0614997148513794\n",
      "Batch : 265, Loss: 1.1455721855163574\n",
      "Batch : 266, Loss: 1.1084216833114624\n",
      "Batch : 267, Loss: 1.147133708000183\n",
      "Batch : 268, Loss: 1.0699152946472168\n",
      "Batch : 269, Loss: 1.1547939777374268\n",
      "Batch : 270, Loss: 1.1119059324264526\n",
      "Batch : 271, Loss: 1.1070891618728638\n",
      "Batch : 272, Loss: 1.027382731437683\n",
      "Batch : 273, Loss: 1.0518651008605957\n",
      "Batch : 274, Loss: 1.1069862842559814\n",
      "Batch : 275, Loss: 0.9520145058631897\n",
      "Batch : 276, Loss: 1.0975385904312134\n",
      "Batch : 277, Loss: 1.0851521492004395\n",
      "Batch : 278, Loss: 1.054248571395874\n",
      "Batch : 279, Loss: 1.0505740642547607\n",
      "Batch : 280, Loss: 1.222033977508545\n",
      "Batch : 281, Loss: 1.0501341819763184\n",
      "Batch : 282, Loss: 1.1541465520858765\n",
      "Batch : 283, Loss: 1.0036944150924683\n",
      "Batch : 284, Loss: 1.0413174629211426\n",
      "Batch : 285, Loss: 1.056823968887329\n",
      "Batch : 286, Loss: 1.1081955432891846\n",
      "Batch : 287, Loss: 0.9145088195800781\n",
      "Batch : 288, Loss: 1.1203029155731201\n",
      "Batch : 289, Loss: 1.1103918552398682\n",
      "Batch : 290, Loss: 1.120837688446045\n",
      "Batch : 291, Loss: 1.0900177955627441\n",
      "Batch : 292, Loss: 0.9630254507064819\n",
      "Batch : 293, Loss: 1.0491408109664917\n",
      "Batch : 294, Loss: 1.0795146226882935\n",
      "Batch : 295, Loss: 1.0308870077133179\n",
      "Batch : 296, Loss: 1.016690969467163\n",
      "Batch : 297, Loss: 1.0249649286270142\n",
      "Batch : 298, Loss: 1.0618194341659546\n",
      "Batch : 299, Loss: 0.9712750315666199\n",
      "Batch : 300, Loss: 1.1576679944992065\n",
      "Batch : 301, Loss: 0.9829971790313721\n",
      "Batch : 302, Loss: 0.9850505590438843\n",
      "Batch : 303, Loss: 0.9846041798591614\n",
      "Batch : 304, Loss: 0.8743593692779541\n",
      "Batch : 305, Loss: 0.962864100933075\n",
      "Batch : 306, Loss: 1.010254144668579\n",
      "Batch : 307, Loss: 1.0945557355880737\n",
      "Batch : 308, Loss: 0.9639612436294556\n",
      "Batch : 309, Loss: 0.9142683148384094\n",
      "Batch : 310, Loss: 1.028632402420044\n",
      "Batch : 311, Loss: 1.163886547088623\n",
      "Batch : 312, Loss: 0.8537325263023376\n",
      "Batch : 313, Loss: 0.9889673590660095\n",
      "Batch : 314, Loss: 1.0357553958892822\n",
      "Batch : 315, Loss: 0.9373365044593811\n",
      "Batch : 316, Loss: 0.949389636516571\n",
      "Batch : 317, Loss: 1.0458372831344604\n",
      "Batch : 318, Loss: 0.8594439029693604\n",
      "Batch : 319, Loss: 1.0614075660705566\n",
      "Batch : 320, Loss: 1.019641399383545\n",
      "Batch : 321, Loss: 0.8771907091140747\n",
      "Batch : 322, Loss: 0.9593406915664673\n",
      "Batch : 323, Loss: 0.9212976694107056\n",
      "Batch : 324, Loss: 0.8434723615646362\n",
      "Batch : 325, Loss: 0.8968423008918762\n",
      "Batch : 326, Loss: 0.9514906406402588\n",
      "Batch : 327, Loss: 1.0096849203109741\n",
      "Batch : 328, Loss: 0.955115020275116\n",
      "Batch : 329, Loss: 0.8126899003982544\n",
      "Batch : 330, Loss: 0.927213191986084\n",
      "Batch : 331, Loss: 1.0267572402954102\n",
      "Batch : 332, Loss: 1.0237979888916016\n",
      "Batch : 333, Loss: 0.9231650829315186\n",
      "Batch : 334, Loss: 1.0199034214019775\n",
      "Batch : 335, Loss: 0.9712200164794922\n",
      "Batch : 336, Loss: 0.8677980899810791\n",
      "Batch : 337, Loss: 0.8132036924362183\n",
      "Batch : 338, Loss: 0.9959396123886108\n",
      "Batch : 339, Loss: 0.8140525221824646\n",
      "Batch : 340, Loss: 0.9478808045387268\n",
      "Batch : 341, Loss: 0.9909131526947021\n",
      "Batch : 342, Loss: 0.9696119427680969\n",
      "Batch : 343, Loss: 0.8024156093597412\n",
      "Batch : 344, Loss: 0.8099087476730347\n",
      "Batch : 345, Loss: 0.8380036354064941\n",
      "Batch : 346, Loss: 0.8745460510253906\n",
      "Batch : 347, Loss: 0.972987711429596\n",
      "Batch : 348, Loss: 1.0200058221817017\n",
      "Batch : 349, Loss: 0.974635899066925\n",
      "Batch : 350, Loss: 0.8554897904396057\n",
      "Batch : 351, Loss: 0.9206744432449341\n",
      "Batch : 352, Loss: 0.8898870944976807\n",
      "Batch : 353, Loss: 0.8898094892501831\n",
      "Batch : 354, Loss: 0.8383221626281738\n",
      "Batch : 355, Loss: 0.9569494724273682\n",
      "Batch : 356, Loss: 0.9764468669891357\n",
      "Batch : 357, Loss: 0.8095207214355469\n",
      "Batch : 358, Loss: 0.8845278024673462\n",
      "Batch : 359, Loss: 0.976321280002594\n",
      "Batch : 360, Loss: 0.8531783819198608\n",
      "Batch : 361, Loss: 0.9209612607955933\n",
      "Batch : 362, Loss: 0.9221140146255493\n",
      "Batch : 363, Loss: 0.8862188458442688\n",
      "Batch : 364, Loss: 0.8837239742279053\n",
      "Batch : 365, Loss: 0.9070107340812683\n",
      "Batch : 366, Loss: 1.0583338737487793\n",
      "Batch : 367, Loss: 0.8037051558494568\n",
      "Batch : 368, Loss: 0.8907573819160461\n",
      "Batch : 369, Loss: 0.8890904188156128\n",
      "Batch : 370, Loss: 0.8850364685058594\n",
      "Batch : 371, Loss: 0.9492731094360352\n",
      "Batch : 372, Loss: 0.831713080406189\n",
      "Batch : 373, Loss: 0.814044177532196\n",
      "Batch : 374, Loss: 0.8138951659202576\n",
      "Batch : 375, Loss: 0.76637864112854\n",
      "Batch : 376, Loss: 0.8652927279472351\n",
      "Batch : 377, Loss: 0.9430568218231201\n",
      "Batch : 378, Loss: 0.8855245113372803\n",
      "Batch : 379, Loss: 0.7675840854644775\n",
      "Batch : 380, Loss: 0.813883900642395\n",
      "Batch : 381, Loss: 0.9329831600189209\n",
      "Batch : 382, Loss: 0.8648528456687927\n",
      "Batch : 383, Loss: 0.9245061874389648\n",
      "Batch : 384, Loss: 0.7726048231124878\n",
      "Batch : 385, Loss: 0.8979705572128296\n",
      "Batch : 386, Loss: 0.8881397843360901\n",
      "Batch : 387, Loss: 0.5930456519126892\n",
      "Batch : 388, Loss: 0.8916354775428772\n",
      "Batch : 389, Loss: 0.8953877091407776\n",
      "Batch : 390, Loss: 0.9833217859268188\n",
      "Batch : 391, Loss: 0.8635151982307434\n",
      "Batch : 392, Loss: 0.8726015090942383\n",
      "Batch : 393, Loss: 0.9265116453170776\n",
      "Batch : 394, Loss: 0.9165986180305481\n",
      "Batch : 395, Loss: 0.9602241516113281\n",
      "Batch : 396, Loss: 0.7581108212471008\n",
      "Batch : 397, Loss: 0.8307162523269653\n",
      "Batch : 398, Loss: 0.7295326590538025\n",
      "Batch : 399, Loss: 0.9735192060470581\n",
      "Batch : 400, Loss: 0.9311831593513489\n",
      "Batch : 401, Loss: 0.7892268300056458\n",
      "Batch : 402, Loss: 0.8174136281013489\n",
      "Batch : 403, Loss: 0.8859277367591858\n",
      "Batch : 404, Loss: 0.7848237156867981\n",
      "Batch : 405, Loss: 0.7618469595909119\n",
      "Batch : 406, Loss: 0.9261286854743958\n",
      "Batch : 407, Loss: 0.8848837018013\n",
      "Batch : 408, Loss: 0.8116838335990906\n",
      "Batch : 409, Loss: 0.9706552028656006\n",
      "Batch : 410, Loss: 0.7818617224693298\n",
      "Batch : 411, Loss: 0.7935642004013062\n",
      "Batch : 412, Loss: 0.8096001744270325\n",
      "Batch : 413, Loss: 0.9496797919273376\n",
      "Batch : 414, Loss: 0.9742069244384766\n",
      "Batch : 415, Loss: 0.9207967519760132\n",
      "Batch : 416, Loss: 0.8661067485809326\n",
      "Batch : 417, Loss: 0.9042625427246094\n",
      "Batch : 418, Loss: 0.7973629832267761\n",
      "Batch : 419, Loss: 0.8236547112464905\n",
      "Batch : 420, Loss: 0.9066341519355774\n",
      "Batch : 421, Loss: 0.7529654502868652\n",
      "Batch : 422, Loss: 1.050246000289917\n",
      "Batch : 423, Loss: 0.7594790458679199\n",
      "Batch : 424, Loss: 0.6818046569824219\n",
      "Batch : 425, Loss: 0.9556789398193359\n",
      "Batch : 426, Loss: 0.7378793358802795\n",
      "Batch : 427, Loss: 0.8432635068893433\n",
      "Batch : 428, Loss: 0.8815158605575562\n",
      "Batch : 429, Loss: 0.8360068798065186\n",
      "Batch : 430, Loss: 0.810179591178894\n",
      "Batch : 431, Loss: 0.7583208084106445\n",
      "Batch : 432, Loss: 0.67996746301651\n",
      "Batch : 433, Loss: 0.8866943120956421\n",
      "Batch : 434, Loss: 0.710419237613678\n",
      "Batch : 435, Loss: 0.8478832244873047\n",
      "Batch : 436, Loss: 0.8804984092712402\n",
      "Batch : 437, Loss: 0.9713487029075623\n",
      "Batch : 438, Loss: 0.8540480732917786\n",
      "Batch : 439, Loss: 0.8773731589317322\n",
      "Batch : 440, Loss: 0.8507721424102783\n",
      "Batch : 441, Loss: 0.8653823733329773\n",
      "Batch : 442, Loss: 0.7158947587013245\n",
      "Batch : 443, Loss: 0.859886109828949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 444, Loss: 0.7245967388153076\n",
      "Batch : 445, Loss: 0.8864848613739014\n",
      "Batch : 446, Loss: 0.718429684638977\n",
      "Batch : 447, Loss: 0.8926407694816589\n",
      "Batch : 448, Loss: 0.8970000147819519\n",
      "Batch : 449, Loss: 0.8987643718719482\n",
      "Batch : 450, Loss: 0.8502406477928162\n",
      "Batch : 451, Loss: 0.9641009569168091\n",
      "Batch : 452, Loss: 1.0616514682769775\n",
      "Batch : 453, Loss: 0.778825581073761\n",
      "Batch : 454, Loss: 0.8337017893791199\n",
      "Batch : 455, Loss: 0.9947903156280518\n",
      "Batch : 456, Loss: 0.720909595489502\n",
      "Batch : 457, Loss: 0.7365311980247498\n",
      "Batch : 458, Loss: 0.7314582467079163\n",
      "Batch : 459, Loss: 0.7165642380714417\n",
      "Batch : 460, Loss: 0.6830765604972839\n",
      "Batch : 461, Loss: 0.7995732426643372\n",
      "Batch : 462, Loss: 0.8471102118492126\n",
      "Batch : 463, Loss: 1.0199472904205322\n",
      "Batch : 464, Loss: 0.8130252361297607\n",
      "Batch : 465, Loss: 0.8570309281349182\n",
      "Batch : 466, Loss: 0.7960633039474487\n",
      "Batch : 467, Loss: 0.8797236680984497\n",
      "Batch : 468, Loss: 0.8675035238265991\n",
      "Batch : 469, Loss: 0.8153274059295654\n",
      "Batch : 470, Loss: 0.772689938545227\n",
      "Batch : 471, Loss: 0.7840290069580078\n",
      "Batch : 472, Loss: 0.7477915287017822\n",
      "Batch : 473, Loss: 0.8931936025619507\n",
      "Batch : 474, Loss: 0.782498300075531\n",
      "Batch : 475, Loss: 0.7840028405189514\n",
      "Batch : 476, Loss: 0.7334317564964294\n",
      "Batch : 477, Loss: 0.7418493628501892\n",
      "Batch : 478, Loss: 0.7301085591316223\n",
      "Batch : 479, Loss: 0.8649996519088745\n",
      "Batch : 480, Loss: 0.7663862109184265\n",
      "Batch : 481, Loss: 0.6765788793563843\n",
      "Batch : 482, Loss: 0.826831042766571\n",
      "Batch : 483, Loss: 0.8151810765266418\n",
      "Batch : 484, Loss: 0.8254557251930237\n",
      "Batch : 485, Loss: 0.6248900294303894\n",
      "Batch : 486, Loss: 0.744583010673523\n",
      "Batch : 487, Loss: 0.7726086378097534\n",
      "Batch : 488, Loss: 0.6416921615600586\n",
      "Batch : 489, Loss: 0.8319398760795593\n",
      "Batch : 490, Loss: 0.7449011206626892\n",
      "Batch : 491, Loss: 0.5867342352867126\n",
      "Batch : 492, Loss: 0.6816710233688354\n",
      "Batch : 493, Loss: 0.7500202059745789\n",
      "Batch : 494, Loss: 0.6333205699920654\n",
      "Batch : 495, Loss: 0.9037579894065857\n",
      "Batch : 496, Loss: 0.9408153891563416\n",
      "Batch : 497, Loss: 0.7833501696586609\n",
      "Batch : 498, Loss: 0.770412266254425\n",
      "Batch : 499, Loss: 0.795487105846405\n",
      "Batch : 500, Loss: 0.8290451765060425\n",
      "Batch : 501, Loss: 0.687729001045227\n",
      "Batch : 502, Loss: 0.6725992560386658\n",
      "Batch : 503, Loss: 0.7377816438674927\n",
      "Batch : 504, Loss: 0.7884173393249512\n",
      "Batch : 505, Loss: 0.8771483302116394\n",
      "Batch : 506, Loss: 0.7340989112854004\n",
      "Batch : 507, Loss: 0.674940824508667\n",
      "Batch : 508, Loss: 0.9705939888954163\n",
      "Batch : 509, Loss: 0.7335062623023987\n",
      "Batch : 510, Loss: 0.8186115622520447\n",
      "Batch : 511, Loss: 0.8453865647315979\n",
      "Batch : 512, Loss: 0.7328284382820129\n",
      "Batch : 513, Loss: 0.915651798248291\n",
      "Batch : 514, Loss: 0.7034273743629456\n",
      "Batch : 515, Loss: 0.9119855165481567\n",
      "Batch : 516, Loss: 0.8239476084709167\n",
      "Batch : 517, Loss: 0.8063986301422119\n",
      "Batch : 518, Loss: 0.7937206029891968\n",
      "Batch : 519, Loss: 0.6414893269538879\n",
      "Batch : 520, Loss: 0.7318383455276489\n",
      "Batch : 521, Loss: 0.5817010402679443\n",
      "Batch : 522, Loss: 0.7684504985809326\n",
      "Batch : 523, Loss: 0.8620225787162781\n",
      "Batch : 524, Loss: 0.8953003883361816\n",
      "Batch : 525, Loss: 0.8035270571708679\n",
      "Batch : 526, Loss: 0.6607702374458313\n",
      "Batch : 527, Loss: 0.7895902991294861\n",
      "Batch : 528, Loss: 0.5994604825973511\n",
      "Batch : 529, Loss: 0.7110291719436646\n",
      "Batch : 530, Loss: 0.812314510345459\n",
      "Batch : 531, Loss: 0.812604546546936\n",
      "Batch : 532, Loss: 0.6989706754684448\n",
      "Batch : 533, Loss: 0.6484799981117249\n",
      "Batch : 534, Loss: 0.6982521414756775\n",
      "Batch : 535, Loss: 0.6976444721221924\n",
      "Batch : 536, Loss: 0.6069861650466919\n",
      "Batch : 537, Loss: 0.7699623703956604\n",
      "Batch : 538, Loss: 0.7679441571235657\n",
      "Batch : 539, Loss: 0.571792483329773\n",
      "Batch : 540, Loss: 0.6567666530609131\n",
      "Batch : 541, Loss: 0.6277428865432739\n",
      "Batch : 542, Loss: 0.6774905920028687\n",
      "Batch : 543, Loss: 0.792579710483551\n",
      "Batch : 544, Loss: 0.7022404074668884\n",
      "Batch : 545, Loss: 0.8555465936660767\n",
      "Batch : 546, Loss: 0.8046762347221375\n",
      "Batch : 547, Loss: 0.8353305459022522\n",
      "Batch : 548, Loss: 0.7809866666793823\n",
      "Batch : 549, Loss: 0.7164933085441589\n",
      "Batch : 550, Loss: 0.6068886518478394\n",
      "Batch : 551, Loss: 0.8147357106208801\n",
      "Batch : 552, Loss: 0.6828210353851318\n",
      "Batch : 553, Loss: 0.6909176111221313\n",
      "Batch : 554, Loss: 0.6246188879013062\n",
      "Batch : 555, Loss: 0.6802390813827515\n",
      "Batch : 556, Loss: 0.5987704396247864\n",
      "Batch : 557, Loss: 0.6238289475440979\n",
      "Batch : 558, Loss: 0.8076397776603699\n",
      "Batch : 559, Loss: 0.7598494291305542\n",
      "Batch : 560, Loss: 0.731079638004303\n",
      "Batch : 561, Loss: 0.6258247494697571\n",
      "Batch : 562, Loss: 0.565999448299408\n",
      "Batch : 563, Loss: 0.8234044909477234\n",
      "Batch : 564, Loss: 0.7149004340171814\n",
      "Batch : 565, Loss: 0.7078766822814941\n",
      "Batch : 566, Loss: 0.7060557007789612\n",
      "Batch : 567, Loss: 0.7098417282104492\n",
      "Batch : 568, Loss: 0.6774249076843262\n",
      "Batch : 569, Loss: 0.767624020576477\n",
      "Batch : 570, Loss: 0.6199659705162048\n",
      "Batch : 571, Loss: 0.7859252095222473\n",
      "Batch : 572, Loss: 0.6211647391319275\n",
      "Batch : 573, Loss: 0.7782103419303894\n",
      "Batch : 574, Loss: 0.6761878728866577\n",
      "Batch : 575, Loss: 0.7680578231811523\n",
      "Batch : 576, Loss: 0.728506326675415\n",
      "Batch : 577, Loss: 0.6804848909378052\n",
      "Batch : 578, Loss: 0.743339478969574\n",
      "Batch : 579, Loss: 0.7413204908370972\n",
      "Batch : 580, Loss: 0.6562045216560364\n",
      "Batch : 581, Loss: 0.8699349164962769\n",
      "Batch : 582, Loss: 0.5908172130584717\n",
      "Batch : 583, Loss: 0.6817599534988403\n",
      "Batch : 584, Loss: 0.7462961077690125\n",
      "Batch : 585, Loss: 0.6454450488090515\n",
      "Batch : 586, Loss: 0.6230085492134094\n",
      "Batch : 587, Loss: 0.616416335105896\n",
      "Batch : 588, Loss: 0.8518407940864563\n",
      "Batch : 589, Loss: 0.7411338686943054\n",
      "Batch : 590, Loss: 0.6432503461837769\n",
      "Batch : 591, Loss: 0.8336545825004578\n",
      "Batch : 592, Loss: 0.6789819598197937\n",
      "Batch : 593, Loss: 0.7134862542152405\n",
      "Batch : 594, Loss: 0.7939903736114502\n",
      "Batch : 595, Loss: 1.0824227333068848\n",
      "Batch : 596, Loss: 0.8264767527580261\n",
      "Batch : 597, Loss: 0.6745511889457703\n",
      "Batch : 598, Loss: 0.7995464205741882\n",
      "Batch : 599, Loss: 0.7544606328010559\n",
      "Batch : 600, Loss: 0.6810399889945984\n",
      "Batch : 601, Loss: 0.5973367691040039\n",
      "Batch : 602, Loss: 0.6499874591827393\n",
      "Batch : 603, Loss: 0.8526818156242371\n",
      "Batch : 604, Loss: 0.737087607383728\n",
      "Batch : 605, Loss: 0.7197889685630798\n",
      "Batch : 606, Loss: 0.9105743169784546\n",
      "Batch : 607, Loss: 0.5814118981361389\n",
      "Batch : 608, Loss: 0.7270674109458923\n",
      "Batch : 609, Loss: 0.9150997996330261\n",
      "Batch : 610, Loss: 0.7488572597503662\n",
      "Batch : 611, Loss: 0.6062048673629761\n",
      "Batch : 612, Loss: 0.6291254758834839\n",
      "Batch : 613, Loss: 0.5829024314880371\n",
      "Batch : 614, Loss: 0.9954738020896912\n",
      "Batch : 615, Loss: 0.7367667555809021\n",
      "Batch : 616, Loss: 0.6384955644607544\n",
      "Batch : 617, Loss: 0.7152849435806274\n",
      "Batch : 618, Loss: 0.6518800854682922\n",
      "Batch : 619, Loss: 0.6057723760604858\n",
      "Batch : 620, Loss: 0.8240856528282166\n",
      "Batch : 621, Loss: 0.7041902542114258\n",
      "Batch : 622, Loss: 0.7517197132110596\n",
      "Batch : 623, Loss: 0.7833099961280823\n",
      "Batch : 624, Loss: 0.6563698649406433\n",
      "Batch : 625, Loss: 0.8303229212760925\n",
      "Batch : 626, Loss: 0.595137357711792\n",
      "Batch : 627, Loss: 0.7508023977279663\n",
      "Batch : 628, Loss: 0.7592976093292236\n",
      "Batch : 629, Loss: 0.8066631555557251\n",
      "Batch : 630, Loss: 0.7289208769798279\n",
      "Batch : 631, Loss: 0.702649712562561\n",
      "Batch : 632, Loss: 0.5818814039230347\n",
      "Batch : 633, Loss: 0.7140017151832581\n",
      "Batch : 634, Loss: 0.6643520593643188\n",
      "Batch : 635, Loss: 0.6606740355491638\n",
      "Batch : 636, Loss: 0.6655247211456299\n",
      "Batch : 637, Loss: 0.7239311337471008\n",
      "Batch : 638, Loss: 0.7418044209480286\n",
      "Batch : 639, Loss: 0.8062152862548828\n",
      "Batch : 640, Loss: 0.7050405144691467\n",
      "Batch : 641, Loss: 0.5876792669296265\n",
      "Batch : 642, Loss: 0.5976606011390686\n",
      "Batch : 643, Loss: 0.7713596224784851\n",
      "Batch : 644, Loss: 0.7743173837661743\n",
      "Batch : 645, Loss: 0.5888047218322754\n",
      "Batch : 646, Loss: 0.7421723008155823\n",
      "Batch : 647, Loss: 0.7785388827323914\n",
      "Batch : 648, Loss: 0.7140816450119019\n",
      "Batch : 649, Loss: 0.7944451570510864\n",
      "Batch : 650, Loss: 0.6026971340179443\n",
      "Batch : 651, Loss: 0.6955149173736572\n",
      "Batch : 652, Loss: 0.5489134192466736\n",
      "Batch : 653, Loss: 0.7899935841560364\n",
      "Batch : 654, Loss: 0.49408793449401855\n",
      "Batch : 655, Loss: 0.5722878575325012\n",
      "Batch : 656, Loss: 0.6144441366195679\n",
      "Batch : 657, Loss: 0.5623335242271423\n",
      "Batch : 658, Loss: 0.6599313616752625\n",
      "Batch : 659, Loss: 0.6563077569007874\n",
      "Batch : 660, Loss: 0.6379177570343018\n",
      "Batch : 661, Loss: 0.7641077637672424\n",
      "Batch : 662, Loss: 0.5449545383453369\n",
      "Batch : 663, Loss: 0.8047577738761902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 664, Loss: 0.7841007113456726\n",
      "Batch : 665, Loss: 0.6506662964820862\n",
      "Batch : 666, Loss: 0.7307195067405701\n",
      "Batch : 667, Loss: 0.6410345435142517\n",
      "Batch : 668, Loss: 0.7250717878341675\n",
      "Batch : 669, Loss: 0.6768350601196289\n",
      "Batch : 670, Loss: 0.6231622695922852\n",
      "Batch : 671, Loss: 0.5729408264160156\n",
      "Batch : 672, Loss: 0.8174839019775391\n",
      "Batch : 673, Loss: 0.6933030486106873\n",
      "Batch : 674, Loss: 0.7175322771072388\n",
      "Batch : 675, Loss: 0.946224570274353\n",
      "Batch : 676, Loss: 0.7622087597846985\n",
      "Batch : 677, Loss: 0.7000573873519897\n",
      "Batch : 678, Loss: 0.7299891114234924\n",
      "Batch : 679, Loss: 0.6694550514221191\n",
      "Batch : 680, Loss: 0.8548479676246643\n",
      "Batch : 681, Loss: 0.6192858219146729\n",
      "Batch : 682, Loss: 0.5953477621078491\n",
      "Batch : 683, Loss: 0.6394705176353455\n",
      "Batch : 684, Loss: 0.6285605430603027\n",
      "Batch : 685, Loss: 0.6416627764701843\n",
      "Batch : 686, Loss: 0.7026252746582031\n",
      "Batch : 687, Loss: 0.8573551774024963\n",
      "Batch : 688, Loss: 0.7493316531181335\n",
      "Batch : 689, Loss: 0.6379758715629578\n",
      "Batch : 690, Loss: 0.7253845930099487\n",
      "Batch : 691, Loss: 0.722724199295044\n",
      "Batch : 692, Loss: 0.7228804230690002\n",
      "Batch : 693, Loss: 0.7634343504905701\n",
      "Batch : 694, Loss: 0.7037131190299988\n",
      "Batch : 695, Loss: 0.751334011554718\n",
      "Batch : 696, Loss: 0.8502045273780823\n",
      "Batch : 697, Loss: 0.698296070098877\n",
      "Batch : 698, Loss: 0.7246081829071045\n",
      "Batch : 699, Loss: 0.8579838871955872\n",
      "Batch : 700, Loss: 0.8512060046195984\n",
      "Batch : 701, Loss: 0.6325383186340332\n",
      "Batch : 702, Loss: 0.6060781478881836\n",
      "Batch : 703, Loss: 0.642543375492096\n",
      "Batch : 704, Loss: 0.6040456295013428\n",
      "Batch : 705, Loss: 0.6563869714736938\n",
      "Batch : 706, Loss: 0.6933591365814209\n",
      "Batch : 707, Loss: 0.6598309278488159\n",
      "Batch : 708, Loss: 0.7111905813217163\n",
      "Batch : 709, Loss: 0.7098947763442993\n",
      "Batch : 710, Loss: 0.5268942713737488\n",
      "Batch : 711, Loss: 0.5999324917793274\n",
      "Batch : 712, Loss: 0.5754702687263489\n",
      "Batch : 713, Loss: 0.686796247959137\n",
      "Batch : 714, Loss: 0.8459368944168091\n",
      "Batch : 715, Loss: 0.8453646898269653\n",
      "Batch : 716, Loss: 0.5135639905929565\n",
      "Batch : 717, Loss: 0.6772300004959106\n",
      "Batch : 718, Loss: 0.8599544167518616\n",
      "Batch : 719, Loss: 0.6653790473937988\n",
      "Batch : 720, Loss: 0.589418351650238\n",
      "Batch : 721, Loss: 0.5106611251831055\n",
      "Batch : 722, Loss: 0.7208072543144226\n",
      "Batch : 723, Loss: 0.7574284672737122\n",
      "Batch : 724, Loss: 0.5713109970092773\n",
      "Batch : 725, Loss: 0.6344876289367676\n",
      "Batch : 726, Loss: 0.7381584048271179\n",
      "Batch : 727, Loss: 0.6380841135978699\n",
      "Batch : 728, Loss: 0.46753814816474915\n",
      "Batch : 729, Loss: 0.5607509016990662\n",
      "Batch : 730, Loss: 0.7164881825447083\n",
      "Batch : 731, Loss: 0.5633676648139954\n",
      "Batch : 732, Loss: 0.5870952606201172\n",
      "Batch : 733, Loss: 0.5883274078369141\n",
      "Batch : 734, Loss: 0.6148626208305359\n",
      "Batch : 735, Loss: 0.7213939428329468\n",
      "Batch : 736, Loss: 0.4307797849178314\n",
      "Batch : 737, Loss: 0.6481360793113708\n",
      "Batch : 738, Loss: 0.6371394395828247\n",
      "Batch : 739, Loss: 0.6756975054740906\n",
      "Batch : 740, Loss: 0.7486546635627747\n",
      "Batch : 741, Loss: 0.6897315979003906\n",
      "Batch : 742, Loss: 0.6026532053947449\n",
      "Batch : 743, Loss: 0.6625153422355652\n",
      "Batch : 744, Loss: 0.6829923391342163\n",
      "Batch : 745, Loss: 0.526500403881073\n",
      "Batch : 746, Loss: 0.790939211845398\n",
      "Batch : 747, Loss: 0.5677817463874817\n",
      "Batch : 748, Loss: 0.7619798183441162\n",
      "Batch : 749, Loss: 0.6309338212013245\n",
      "Batch : 750, Loss: 0.7070701718330383\n",
      "Batch : 751, Loss: 0.773996889591217\n",
      "Batch : 752, Loss: 0.5577032566070557\n",
      "Batch : 753, Loss: 0.5310572981834412\n",
      "Batch : 754, Loss: 0.6217383742332458\n",
      "Batch : 755, Loss: 0.8579649329185486\n",
      "Batch : 756, Loss: 0.9663988947868347\n",
      "Batch : 757, Loss: 0.6411929726600647\n",
      "Batch : 758, Loss: 0.6794131994247437\n",
      "Batch : 759, Loss: 0.6280460357666016\n",
      "Batch : 760, Loss: 0.6839550137519836\n",
      "Batch : 761, Loss: 0.78572678565979\n",
      "Batch : 762, Loss: 0.5712286233901978\n",
      "Batch : 763, Loss: 0.5666866302490234\n",
      "Batch : 764, Loss: 0.7862237691879272\n",
      "Batch : 765, Loss: 0.6183480024337769\n",
      "Batch : 766, Loss: 0.6539973020553589\n",
      "Batch : 767, Loss: 0.5405644774436951\n",
      "Batch : 768, Loss: 0.5332087278366089\n",
      "Batch : 769, Loss: 0.6553702354431152\n",
      "Batch : 770, Loss: 0.7181804776191711\n",
      "Batch : 771, Loss: 0.6026461124420166\n",
      "Batch : 772, Loss: 0.6189404726028442\n",
      "Batch : 773, Loss: 0.6852995753288269\n",
      "Batch : 774, Loss: 0.7801007032394409\n",
      "Batch : 775, Loss: 0.7938510775566101\n",
      "Batch : 776, Loss: 0.5412639379501343\n",
      "Batch : 777, Loss: 0.6222010850906372\n",
      "Batch : 778, Loss: 0.6346478462219238\n",
      "Batch : 779, Loss: 0.7856621742248535\n",
      "Batch : 780, Loss: 0.5848755836486816\n",
      "Batch : 781, Loss: 0.628122866153717\n",
      "Batch : 782, Loss: 0.6542067527770996\n",
      "Batch : 783, Loss: 0.494281142950058\n",
      "Batch : 784, Loss: 0.6025489568710327\n",
      "Batch : 785, Loss: 0.4379267394542694\n",
      "Batch : 786, Loss: 0.7119565606117249\n",
      "Batch : 787, Loss: 0.6327111124992371\n",
      "Batch : 788, Loss: 0.7229312062263489\n",
      "Batch : 789, Loss: 0.5683900117874146\n",
      "Batch : 790, Loss: 0.6728331446647644\n",
      "Batch : 791, Loss: 0.7412009835243225\n",
      "Batch : 792, Loss: 0.6553446054458618\n",
      "Batch : 793, Loss: 0.5619264841079712\n",
      "Batch : 794, Loss: 0.6990686058998108\n",
      "Batch : 795, Loss: 0.7397725582122803\n",
      "Batch : 796, Loss: 0.7853190898895264\n",
      "Batch : 797, Loss: 0.4593219757080078\n",
      "Batch : 798, Loss: 0.7962051630020142\n",
      "Batch : 799, Loss: 0.850084662437439\n",
      "Batch : 800, Loss: 0.644173264503479\n",
      "Batch : 801, Loss: 0.7752112150192261\n",
      "Batch : 802, Loss: 0.6062241196632385\n",
      "Batch : 803, Loss: 0.5656178593635559\n",
      "Batch : 804, Loss: 0.5906229615211487\n",
      "Batch : 805, Loss: 0.8203229904174805\n",
      "Batch : 806, Loss: 0.7541404962539673\n",
      "Batch : 807, Loss: 0.7168056964874268\n",
      "Batch : 808, Loss: 0.7375170588493347\n",
      "Batch : 809, Loss: 0.6201417446136475\n",
      "Batch : 810, Loss: 0.6517826318740845\n",
      "Batch : 811, Loss: 0.6451361775398254\n",
      "Batch : 812, Loss: 0.7428853511810303\n",
      "Batch : 813, Loss: 0.8247106075286865\n",
      "Batch : 814, Loss: 0.5603293776512146\n",
      "Batch : 815, Loss: 0.6148913502693176\n",
      "Batch : 816, Loss: 0.6041668653488159\n",
      "Batch : 817, Loss: 0.4878513216972351\n",
      "Batch : 818, Loss: 0.6280779838562012\n",
      "Batch : 819, Loss: 0.49517783522605896\n",
      "Batch : 820, Loss: 0.6525704264640808\n",
      "Batch : 821, Loss: 0.642062246799469\n",
      "Batch : 822, Loss: 0.5988874435424805\n",
      "Batch : 823, Loss: 0.8140575289726257\n",
      "Batch : 824, Loss: 0.6401622295379639\n",
      "Batch : 825, Loss: 0.7517709136009216\n",
      "Batch : 826, Loss: 0.508342444896698\n",
      "Batch : 827, Loss: 0.719398558139801\n",
      "Batch : 828, Loss: 0.5174965262413025\n",
      "Batch : 829, Loss: 0.8147938847541809\n",
      "Batch : 830, Loss: 0.7825590372085571\n",
      "Batch : 831, Loss: 0.6653332710266113\n",
      "Batch : 832, Loss: 0.5786102414131165\n",
      "Batch : 833, Loss: 0.5156089663505554\n",
      "Batch : 834, Loss: 0.5651971101760864\n",
      "Batch : 835, Loss: 0.7195414900779724\n",
      "Batch : 836, Loss: 0.69033282995224\n",
      "Batch : 837, Loss: 0.5901259183883667\n",
      "Batch : 838, Loss: 0.5502374768257141\n",
      "Batch : 839, Loss: 0.5123553276062012\n",
      "Batch : 840, Loss: 0.6042708158493042\n",
      "Batch : 841, Loss: 0.7666295170783997\n",
      "Batch : 842, Loss: 0.769445538520813\n",
      "Batch : 843, Loss: 0.4961366653442383\n",
      "Batch : 844, Loss: 0.5649458765983582\n",
      "Batch : 845, Loss: 0.5142069458961487\n",
      "Batch : 846, Loss: 0.5414140224456787\n",
      "Batch : 847, Loss: 0.9004976153373718\n",
      "Batch : 848, Loss: 0.9657650589942932\n",
      "Batch : 849, Loss: 0.6202118992805481\n",
      "Batch : 850, Loss: 0.5530405640602112\n",
      "Batch : 851, Loss: 0.7185742855072021\n",
      "Batch : 852, Loss: 0.7978414297103882\n",
      "Batch : 853, Loss: 0.6578130125999451\n",
      "Batch : 854, Loss: 0.5462313890457153\n",
      "Batch : 855, Loss: 0.5961170792579651\n",
      "Batch : 856, Loss: 0.5518974661827087\n",
      "Batch : 857, Loss: 0.5643539428710938\n",
      "Batch : 858, Loss: 0.473004549741745\n",
      "Batch : 859, Loss: 0.597301721572876\n",
      "Batch : 860, Loss: 0.6967312097549438\n",
      "Batch : 861, Loss: 0.5674178600311279\n",
      "Batch : 862, Loss: 0.6879090666770935\n",
      "Batch : 863, Loss: 0.5958415269851685\n",
      "Batch : 864, Loss: 0.5713783502578735\n",
      "Batch : 865, Loss: 0.8025645613670349\n",
      "Batch : 866, Loss: 0.7217404842376709\n",
      "Batch : 867, Loss: 0.6992794275283813\n",
      "Batch : 868, Loss: 0.619810163974762\n",
      "Batch : 869, Loss: 0.4548332095146179\n",
      "Batch : 870, Loss: 0.6955094337463379\n",
      "Batch : 871, Loss: 0.7798205614089966\n",
      "Batch : 872, Loss: 0.5998345017433167\n",
      "Batch : 873, Loss: 0.7454936504364014\n",
      "Batch : 874, Loss: 1.0852864980697632\n",
      "Batch : 875, Loss: 0.8183249235153198\n",
      "Batch : 876, Loss: 0.6938886642456055\n",
      "Batch : 877, Loss: 0.6240903735160828\n",
      "Batch : 878, Loss: 0.7339156270027161\n",
      "Batch : 879, Loss: 0.6852977275848389\n",
      "Batch : 880, Loss: 0.676050066947937\n",
      "Batch : 881, Loss: 0.4671080410480499\n",
      "Batch : 882, Loss: 0.6529180407524109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch : 883, Loss: 0.5022188425064087\n",
      "Batch : 884, Loss: 0.657915472984314\n",
      "Batch : 885, Loss: 0.7264878749847412\n",
      "Batch : 886, Loss: 0.7783383131027222\n",
      "Batch : 887, Loss: 0.4822810888290405\n",
      "Batch : 888, Loss: 0.5710926055908203\n",
      "Batch : 889, Loss: 0.6394854784011841\n",
      "Batch : 890, Loss: 0.4971812069416046\n",
      "Batch : 891, Loss: 0.5885553359985352\n",
      "Batch : 892, Loss: 0.48457208275794983\n",
      "Batch : 893, Loss: 0.809230387210846\n",
      "Batch : 894, Loss: 0.5771485567092896\n",
      "Batch : 895, Loss: 0.6818283200263977\n",
      "Batch : 896, Loss: 0.9435723423957825\n",
      "Batch : 897, Loss: 0.5399566888809204\n",
      "Batch : 898, Loss: 0.7407468557357788\n",
      "Batch : 899, Loss: 0.5620529055595398\n",
      "Batch : 900, Loss: 0.46863436698913574\n",
      "Batch : 901, Loss: 0.5863428115844727\n",
      "Batch : 902, Loss: 0.5673896670341492\n",
      "Batch : 903, Loss: 0.679092526435852\n",
      "Batch : 904, Loss: 0.5487489700317383\n",
      "Batch : 905, Loss: 0.7344993948936462\n",
      "Batch : 906, Loss: 0.6039249897003174\n",
      "Batch : 907, Loss: 0.6893512010574341\n",
      "Batch : 908, Loss: 0.7184978127479553\n",
      "Batch : 909, Loss: 0.4906938672065735\n",
      "Batch : 910, Loss: 0.48494675755500793\n",
      "Batch : 911, Loss: 0.6423081159591675\n",
      "Batch : 912, Loss: 0.5368221402168274\n",
      "Batch : 913, Loss: 0.46406012773513794\n",
      "Batch : 914, Loss: 0.62005615234375\n",
      "Batch : 915, Loss: 0.7073180079460144\n",
      "Batch : 916, Loss: 0.6444272398948669\n",
      "Batch : 917, Loss: 0.7688653469085693\n",
      "Batch : 918, Loss: 0.6696925759315491\n",
      "Batch : 919, Loss: 0.8276609778404236\n",
      "Batch : 920, Loss: 0.7278871536254883\n",
      "Batch : 921, Loss: 0.5826066732406616\n",
      "Batch : 922, Loss: 0.5325831174850464\n",
      "Batch : 923, Loss: 0.6281423568725586\n",
      "Batch : 924, Loss: 0.5486437082290649\n",
      "Batch : 925, Loss: 0.765691876411438\n",
      "Batch : 926, Loss: 0.5997574329376221\n",
      "Batch : 927, Loss: 0.6178085207939148\n",
      "Batch : 928, Loss: 0.6922202110290527\n",
      "Batch : 929, Loss: 0.4430730938911438\n",
      "Batch : 930, Loss: 0.7469320893287659\n",
      "Batch : 931, Loss: 0.5910533666610718\n",
      "Batch : 932, Loss: 0.5906420946121216\n",
      "Batch : 933, Loss: 0.6463283896446228\n",
      "Batch : 934, Loss: 0.5606772303581238\n",
      "Batch : 935, Loss: 0.4925343096256256\n",
      "Batch : 936, Loss: 0.6765074133872986\n",
      "Batch : 937, Loss: 0.46367043256759644\n",
      "Batch : 938, Loss: 0.5050868391990662\n",
      "Training loss: 1.0307267119190586\n"
     ]
    }
   ],
   "source": [
    "# let's go through it sequentially to see each batch \n",
    "model = FMNIST() # instantiate the class\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1 # change \n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "    batch_num = 0\n",
    "\n",
    "    for batch_num, (images, labels) in enumerate(trainloader,1):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "        print(f'Batch : {batch_num}, Loss: {loss.item()}')\n",
    "       \n",
    "     \n",
    "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "e42a4a9d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-OVDFUnzFGpr"
   },
   "outputs": [],
   "source": [
    "# should see 938 batches because 60000/64 = 937.5\n",
    "# Training loss = average loss for all of the batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea888e",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c557cdea",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCdIqY0tKbvS"
   },
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d34adbe5",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCJzXv0OK1Bs"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30e51d8d",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqMqFbIVrbFH"
   },
   "outputs": [],
   "source": [
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 128)\n",
    "    self.fc2 = nn.Linear(128,64)\n",
    "    self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x # what was missing\n",
    "    \n",
    "model = FMNIST()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41682c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace # use it for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c7246fa1",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJLzWi0UqGWm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9705723759525621\n",
      "Training loss: 0.5528118016559687\n",
      "Training loss: 0.4888261685461632\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        #set_trace()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "     \n",
    "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b55727d5",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWYw7ZOzsS8U"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "test_image_id = 0 \n",
    "img = images[test_image_id].view(1, 784) \n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "737aa617",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tRjoEDSqY8X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1029e-05, 1.0754e-06, 3.0939e-05, 2.3998e-05, 4.3286e-05, 2.1061e-01,\n",
       "         3.1861e-05, 3.4933e-01, 5.3847e-03, 4.3453e-01]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = torch.exp(logps)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fab4748",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpP_RLV-qkc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1028985e-05, 1.0753558e-06, 3.0939282e-05, 2.3998211e-05,\n",
       "       4.3285978e-05, 2.1061036e-01, 3.1860513e-05, 3.4932932e-01,\n",
       "       5.3847106e-03, 4.3453348e-01], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps = ps.numpy()[0]\n",
    "nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "07e48b3e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBf23XrtqrB6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMNIST_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sport Shoe','Bag','Ankle Boot']\n",
    "plt.xticks(np.arange(10),labels=FMNIST_labels,rotation='vertical')\n",
    "plt.bar(np.arange(10), nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a0fb14b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7gY5hARpOp4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21cd6a987f0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def denormalize(tensor):\n",
    "  tensor = tensor*0.5 + 0.5\n",
    "  return tensor\n",
    "  \n",
    "img = img.view(28,-1)\n",
    "img = denormalize(img)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bdb53a",
   "metadata": {},
   "source": [
    "## CPU vs GRU\n",
    "When training models, we often use GPUs. They accelerate existing infrastructure by computing compute-intensive portions of the algorithms.\n",
    "* CPU: for general-purpose computing\n",
    "* GPU: for extensive calsulations such as matrix multiplications\n",
    "\n",
    "### CUDA\n",
    "CUDA is a parallel computing platform and programming model developed by NVidia.\n",
    "\n",
    "* at the top of the notebook, specify the CUDA devie\n",
    "* transfer NN to the GPU\n",
    "* send all inputs and targets to the GPU\n",
    "\n",
    "Training: use GPU memory  \n",
    "Testing: use CPU memory\n",
    "\n",
    "*Models and testing files should be on the same type of memory*\n",
    "\n",
    "---\n",
    "\n",
    "Ways to run the notebook on GPU **in Google Collab**:\n",
    "* Edit -> Notebook Settings -> Hardware Accelerator -> GPU\n",
    "* Runtime -> Change runtime type -> GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f36cc21",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzCCniVwNTdp"
   },
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b2bf425f",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5S4Dfhtg5LyT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6786f81a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCJzXv0OK1Bs"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a879b67",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqMqFbIVrbFH"
   },
   "outputs": [],
   "source": [
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 128)\n",
    "    self.fc2 = nn.Linear(128,64)\n",
    "    self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "model = FMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93b33823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move to GPU memory\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4053db38",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJLzWi0UqGWm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0338174501843036\n",
      "Training loss: 0.5608082033360182\n",
      "Training loss: 0.4914347628699437\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        # move to GPU\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "     \n",
    "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d8824cd",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UreWrEgjqQe3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# should be on CPU from the beginning\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "test_image_id = 0 \n",
    "img = images[test_image_id].view(1, 784) \n",
    "\n",
    "# move back to CPU for testing\n",
    "model.to('cpu')\n",
    "with torch.no_grad():\n",
    "    logps = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "12add5ac",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tRjoEDSqY8X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4896e-06, 5.2015e-07, 8.4381e-06, 8.8204e-07, 5.9689e-06, 1.8997e-01,\n",
       "         4.8245e-06, 1.6213e-01, 4.4144e-03, 6.4347e-01]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = torch.exp(logps)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "25db3e3a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpP_RLV-qkc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4896160e-06, 5.2015196e-07, 8.4380827e-06, 8.8204155e-07,\n",
       "       5.9689005e-06, 1.8996972e-01, 4.8245338e-06, 1.6212720e-01,\n",
       "       4.4143698e-03, 6.4346659e-01], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps = ps.numpy()[0]\n",
    "nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7a7e0a41",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBf23XrtqrB6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMNIST_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sport Shoes','Bag','Ankle Boot']\n",
    "plt.xticks(np.arange(10),labels=FMNIST_labels,rotation='vertical')\n",
    "plt.bar(np.arange(10), nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0820082",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dwV20YRMwq5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21cd6c40f40>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def denormalize(tensor):\n",
    "  tensor = tensor*0.5 + 0.5\n",
    "  return tensor\n",
    "  \n",
    "img = img.view(28,-1)\n",
    "img = denormalize(img)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52419aea",
   "metadata": {},
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ffbf9b9",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzCCniVwNTdp"
   },
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "513fe024",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCJzXv0OK1Bs"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0ae4d38a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqMqFbIVrbFH"
   },
   "outputs": [],
   "source": [
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 128)\n",
    "    self.fc2 = nn.Linear(128,64)\n",
    "    self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "model = FMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c0b6bd96",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNNyI5YRZ7H1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0338174501843036\n",
      "Training loss: 0.5608082033360182\n",
      "Training loss: 0.4914347628699437\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "     \n",
    "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9f3f0146",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWYw7ZOzsS8U"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "test_image_id = 0 \n",
    "img = images[test_image_id].view(1, 784) \n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a662ca6",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tRjoEDSqY8X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4896e-06, 5.2015e-07, 8.4381e-06, 8.8204e-07, 5.9689e-06, 1.8997e-01,\n",
       "         4.8245e-06, 1.6213e-01, 4.4144e-03, 6.4347e-01]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = torch.exp(logps)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "712267a6",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpP_RLV-qkc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4896160e-06, 5.2015196e-07, 8.4380827e-06, 8.8204155e-07,\n",
       "       5.9689005e-06, 1.8996972e-01, 4.8245338e-06, 1.6212720e-01,\n",
       "       4.4143698e-03, 6.4346659e-01], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps = ps.numpy()[0]\n",
    "nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ed26f439",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBf23XrtqrB6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEqCAYAAAAF56vUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfOElEQVR4nO3deZRdZZ3u8e9DAo2COBEFCZiIAUy3gBhQhEYQURA1ggPgQKsoCxVRXLevud0qKtoNTtcW0BgRbJwQ24EoARxABocmAQMyiCtGhjR6CaggiELIc/94dyUnRQ0nWHuf4uX5rJVF7X126vdWqHpqn3e/g2wTEREPfRsMugERETExEugREZVIoEdEVCKBHhFRiQR6REQlEugREZWYOqjCm2++uWfMmDGo8hERD0mXX375bbanjfTawAJ9xowZLFmyZFDlIyIekiTdONpr6XKJiKhEAj0iohIJ9IiISiTQIyIqkUCPiKhEAj0iohIJ9IiISiTQIyIqMbCJRRERk9GMeee0XuOGEw5s5fPmDj0iohIJ9IiISiTQIyIqkUCPiKhEAj0iohIJ9IiISiTQIyIqkUCPiKhEAj0iohIJ9IiISvQV6JL2l3S9pGWS5o1yzd6Slkq6RtJFE9vMiIgYz7hruUiaApwC7AesABZLWmj72p5rHgN8Gtjf9k2SntBSeyMiYhT93KHvBiyzvdz2vcCZwNxh17wa+KbtmwBs3zqxzYyIiPH0E+hbATf3HK9ozvXaDnispB9JulzS4SN9IklHSloiacnKlSsfXIsjImJE/QS6RjjnYcdTgWcCBwIvBN4rabsH/CV7ge05tudMmzZtvRsbERGj62c99BXA1j3H04FbRrjmNtt3A3dLuhjYCfjVhLQyIiLG1c8d+mJglqSZkjYCDgUWDrvmbOAfJU2V9EjgWcB1E9vUiIgYy7h36LZXSToaOB+YApxm+xpJRzWvz7d9naTzgKuA1cCptq9us+EREbGuvrags70IWDTs3Pxhxx8FPjpxTYuIiPWRmaIREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRib4CXdL+kq6XtEzSvBFe31vSHZKWNn/eN/FNjYiIsUwd7wJJU4BTgP2AFcBiSQttXzvs0ktsv7iFNkZERB/6uUPfDVhme7nte4EzgbntNisiItZXP4G+FXBzz/GK5txwu0u6UtK5kv5+pE8k6UhJSyQtWbly5YNobkREjKafQNcI5zzs+ArgybZ3Ak4Cvj3SJ7K9wPYc23OmTZu2Xg2NiIix9RPoK4Cte46nA7f0XmD7Ttt3NR8vAjaUtPmEtTIiIsbVT6AvBmZJmilpI+BQYGHvBZK2kKTm492az3v7RDc2IiJGN+4oF9urJB0NnA9MAU6zfY2ko5rX5wOvAN4iaRVwD3Co7eHdMhER0aJxAx3WdKMsGnZufs/HJwMnT2zTIiJifWSmaEREJRLoERGVSKBHRFQigR4RUYkEekREJRLoERGVSKBHRFQigR4RUYkEekREJRLoERGVSKBHRFQigR4RUYkEekREJRLoERGVSKBHRFQigR4RUYkEekREJRLoERGVSKBHRFQigR4RUYkEekREJRLoERGVSKBHRFSir0CXtL+k6yUtkzRvjOt2lXS/pFdMXBMjIqIf4wa6pCnAKcABwGzgMEmzR7nuROD8iW5kRESMr5879N2AZbaX274XOBOYO8J1bwe+Adw6ge2LiIg+9RPoWwE39xyvaM6tIWkr4CBg/lifSNKRkpZIWrJy5cr1bWtERIyhn0DXCOc87PiTwLtt3z/WJ7K9wPYc23OmTZvWZxMjIqIfU/u4ZgWwdc/xdOCWYdfMAc6UBLA58CJJq2x/eyIaGRER4+sn0BcDsyTNBP4HOBR4de8FtmcOfSzpC8B3E+YREd0aN9Btr5J0NGX0yhTgNNvXSDqqeX3MfvOIiOhGP3fo2F4ELBp2bsQgt/36v71ZERGxvjJTNCKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIirRV6BL2l/S9ZKWSZo3wutzJV0laamkJZL2nPimRkTEWKaOd4GkKcApwH7ACmCxpIW2r+257IfAQtuWtCNwFrBDGw2OiIiR9XOHvhuwzPZy2/cCZwJzey+wfZdtN4ebACYiIjrVT6BvBdzcc7yiObcOSQdJ+iVwDvDGiWleRET0q59A1wjnHnAHbvtbtncAXgYcP+Inko5s+tiXrFy5cr0aGhERY+sn0FcAW/ccTwduGe1i2xcD20rafITXFtieY3vOtGnT1ruxERExun4CfTEwS9JMSRsBhwILey+Q9FRJaj7eBdgIuH2iGxsREaMbd5SL7VWSjgbOB6YAp9m+RtJRzevzgZcDh0u6D7gHOKTnIWlERHRg3EAHsL0IWDTs3Pyej08ETpzYpkVExPrITNGIiEok0CMiKpFAj4ioRAI9IqISCfSIiEok0CMiKpFAj4ioRAI9IqISCfSIiEok0CMiKpFAj4ioRAI9IqISCfSIiEok0CMiKpFAj4ioRAI9IqISCfSIiEok0CMiKpFAj4ioRAI9IqISCfSIiEok0CMiKpFAj4ioRF+BLml/SddLWiZp3givv0bSVc2fn0jaaeKbGhERYxk30CVNAU4BDgBmA4dJmj3sst8Az7W9I3A8sGCiGxoREWPr5w59N2CZ7eW27wXOBOb2XmD7J7b/0Bz+DJg+sc2MiIjx9BPoWwE39xyvaM6N5gjg3L+lURERsf6m9nGNRjjnES+U9qEE+p6jvH4kcCTANtts02cTIyKiH/3coa8Atu45ng7cMvwiSTsCpwJzbd8+0ieyvcD2HNtzpk2b9mDaGxERo+gn0BcDsyTNlLQRcCiwsPcCSdsA3wReZ/tXE9/MiIgYz7hdLrZXSToaOB+YApxm+xpJRzWvzwfeBzwe+LQkgFW257TX7IjuzJh3Tus1bjjhwNZrRP366UPH9iJg0bBz83s+fhPwpoltWkRErI/MFI2IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhK9DUOPSIefjKh6qEnd+gREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRiQR6REQlEugREZVIoEdEVCKBHhFRib4CXdL+kq6XtEzSvBFe30HSTyX9VdL/mvhmRkTEeMbd4ELSFOAUYD9gBbBY0kLb1/Zc9nvgGOBlbTQyIiLG188d+m7AMtvLbd8LnAnM7b3A9q22FwP3tdDGiIjoQz+BvhVwc8/xiuZcRERMIv0EukY45wdTTNKRkpZIWrJy5coH8ykiImIU/QT6CmDrnuPpwC0PppjtBbbn2J4zbdq0B/MpIiJiFP0E+mJglqSZkjYCDgUWttusiIhYX+OOcrG9StLRwPnAFOA029dIOqp5fb6kLYAlwGbAaknvBGbbvrO9pkdERK9xAx3A9iJg0bBz83s+/h2lKyYiIgYkM0UjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhKJNAjIiqRQI+IqEQCPSKiEgn0iIhK9BXokvaXdL2kZZLmjfC6JH2qef0qSbtMfFMjImIs4wa6pCnAKcABwGzgMEmzh112ADCr+XMk8JkJbmdERIxjah/X7AYss70cQNKZwFzg2p5r5gJn2DbwM0mPkbSl7d9OeIsjonoz5p3Teo0bTjiw9Rpd6yfQtwJu7jleATyrj2u2AtYJdElHUu7gAe6SdP16tfZvszlwW4f1Uju1+6YTB1d7Aj2kvu6HcO0nj/ZCP4GuEc75QVyD7QXAgj5qTjhJS2zPSe3UTu3UrqX2cP08FF0BbN1zPB245UFcExERLeon0BcDsyTNlLQRcCiwcNg1C4HDm9EuzwbuSP95RES3xu1ysb1K0tHA+cAU4DTb10g6qnl9PrAIeBGwDPgz8Ib2mvygDaSrJ7VTO7VTuysqA1MiIuKhLjNFIyIqkUCPiKhE1YEuaSNJO0p6evNAt4uaG0h6The1IiaL5vt+s0G34+Gu2kCXdCDwa+BTwMnAMkkHtF3X9mrg423XGU0z0mjr8a+MWkjao59zLdT9iqTNJG1CmTl+vaR/brvuoEnao/makfRaSZ+QNOpkny5V+1BU0i+BF9te1hxvC5xje4cOan8AuAr4pgfwDyzpctvP7LpuU/uVwHm2/yTpPcAuwIdsX9FB7RNtv3u8cxNcc8yF6Dr6uq+wvct451qou9T2zpJeAzwTeDdwue0d26zbU/9dI5y+o2nD0hbrXgXsBOwIfBH4PHCw7ee2VbNf/cwUfai6dSjMG8uBWzuq/S5gE+B+SfdQZtLadldvSX8maVfbizuq1+u9tr8uaU/ghcDHKIu1DV8uog37UUKl1wEjnJtIY70bM/C8tgpL2h14DjBtWLhtRhli3LYNJW0IvAw42fZ9krq8gZnT/PlOc3wgZd7MUZK+bvsjLdVdZduS5gL/Yfvzkv6ppVrrpeZAv0bSIuAsyg/WK4HFkg4GsP3NtgrbflRbn7tP+1C+qW8A7mbtL5Qu7pzub/57IPAZ22dLen+bBSW9BXgr8JTm7mnIo4Aft1nb9j5tfv5xbARsSvk57v2euxN4RQf1PwvcAFwJXNx0O9zZQd0hjwd2sX0XgKTjgP8C9gIuB9oK9D9J+j/Aa4G9mhVpN2yp1nqpucvl9DFetu03tlhbwGuAmbaPb/q0t7R9WVs1h9UfsT/P9o0d1P4u8D/A8ylvw+8BLrO9U4s1Hw08Fvh3oHe9/j/Z/n1bdUdoxz9QlpjeeOic7TNarjkF+JrtLgJ8XJKm2l7VUa3rgJ1s39sc/x2w1PbTJP3c9jNaqrsF8Gpgse1LJG0D7N32/+t+VHuHbnuQs1U/DaymvN0+HriLsqb8rl0Ut31j0+Uxy/bpkqZR7uS68Cpgf+Bjtv8oaUug1Qdltu+g9J0eBiDpCZRQ3VTSprZvarN+U/M4YG9KoC+idPVcCrT6Q277fkmPa7PGaCQ9Efg34Em2D2j2Sdid0qfcha9QuhfPbo5fAny15yFtW47tfS5j+yZJf99ivb7VfIc+HTgJ2IPS5XIp8A7bKzqofYXtXXrvEiRd2eZd6rD6x1H6Fre3vZ2kJwFft93FyIdtgRW2/yppb8qDozNs/7GD2i8BPgE8ifK85MnAdbZb/2GT9AvKg7Kf296pCbtTbb+kg9ofp2wu83VKFxvQbrdiU/dc4HTgX5uveSrl6396m3WHtWEO5WdcwKW2l3RQc6SH0Fd19TB4LNUOW6R8oy2k/HBvRXlwMlY3zES6r3krbIDmDnl1R7UBDgJeSvPDbfsW1u1jbdM3KA+Dn0q5U5tJuZPqwoeAZwO/sj0T2JeW+9B73NMMWV3VjMe+FXhKR7UfB9xOeUf4kubPizuou7nts2i+t5uulvvH/isTqwnwrwLfBG5tuj9aIektzS/u7VW22hz68xvKqLaBq7bLBZhmuzfAvyDpnR3V/hTwLeAJkj5MeUD1no5qA9zbPIUf+oWySYe1VzcLuh0MfNL2SZJ+3lHt+2zf3kxy2cD2hdIEbmMwtiWSHgN8jvJA7i6gk2cmA+xevFvS41l74/JsStdXJyS9lDLKaOgd2TbAL4G23pF9BTiXAT+rGUvNgX6bpNdSfntD6V+9vYvCtr8s6XLKHaKAl9m+rovajbMkfRZ4jKQ3A2+kBE0X7pN0GHA45U4RuhsB8EdJmwKXAF+WdCvQyQM6229tPpwv6TxgM9ut3rVJ+t+2PyLpJEbeUOaYNutThucuBLaV9GNgGt2MrhlyPOUd2Q9sP0PSPjTPUdrQ+6xG0k7APzYvXQJMikCvuQ99G8oM0d0p3+w/AY7p6AHZwPqRe9qwH/ACyi+U821/v6O6s4GjgJ/a/qqkmcAhtk/ooPYmwF8oX/NrgEcDX7bd2i/yQU4skvQS298ZbQy07f9sq3ZPG6YC21P+za+3fV/bNXtqL7E9R9KVwDNsr5Z0me3dWq57DGUrzaFnFAcBC2yf1GbdftQc6HvY/vF451qqvZTyUHIGcB6l/3572y9qu3ZT/1jKQ9DWHwCPUv8RwDa2u9wzdqj2E1k7mugy261OJpN0YfPhxpT/51dSwm1H4L9t79lm/UFqJhW9hTLuG+BHwGe7CnVJP6BMavp3yr6etwK72m51LaVmrsPutu9ujjeh3MDkoWiLRvpt2dVv0NXNA6KDKTPJjgW27Kg2lJmC50u6RNLbmpDrRDPSZCnlFxmSdpY0fIertmq/itJv/UrK8Mn/ltRqF4DtfZrJRTdSJrnMcVl24RmUDV9aJ2k7SQskfU/SBUN/Oij9Gcpcg083f57ZnOvKXMqGOsdSvt9+zdpuvjaJdR/+3s/I+yp3rro+dA1+OjQMth8Z2x8APiBpR+AQ4CJJK2w/v4Py7wd2o9ytYXtp0+3ShX+l3KHdCmtGF/2AMnuwbTvY/sXQge2rJe3cQV0owxXnA6fS7SiTXYcNxb2g6f7oxNAdMrBa0jnA7e6my+F0ys3CtyhBPpfuxt6PqbpAZ/DToaFswXcU8GHbv2kC7Usd1e51K/A7ysPgJ3RUc5XtO6R1bli66tfbYFgXy+109y70OkmnUv4/mzItvKsH4atsd3lnPOR+Sdva/jWApKfQwS+UZjTNCZQHkcdTFsjaHNhA0uG2z2uzvu1PSPoRMNSd9gbbXY3kGlONgb4H5cn7F7qY6j4S29cCx/Qc/4byDdgJlbVNDqGMOvgv4M1Nm7pwtaRXA1MkzaL8O/yko9rnSTqftSObDqHM2uzCGyj9ye9oji+m5e6Hnhmi35H0VspQ2b8Ovd7BULp/Bi6UtJxyp/pkutlP+GTgXygPvS8ADrD9M0k7UP7ftxrojfspv7hNt3NMxlTdQ1FJh1Kmnu9EeUB1LvA923/osA2/YeRhZJ1MNJF0AnCmW1xCdIzaj6R0fbygOXU+Zfncv7RY86nAE23/uBn/viclYP5AGeXy67ZqD1LP99nQ26F1vue6+H5TWT9laJTLL23/dZy/MhE1l9reufn4OttP63mttTVcemq8A3gzZRKdyCiXbkh6BiXcX0DpP/8BZa3uVid8NJMthmxMeUj3ONvva7PusDasM07Wdut9m83s2PM76qvvrftd4F+Gj/tupoUf19H0+z0ozw+eTM873zZDVdJuwM22f9sc/xPwcsoKiO/vYrKLyu5cM1j3a257QbI1U+81bBr+8OOW6k/aUS7VBrqkv+u9W1CZjv1SYC/bRw6gPZd2NYRtkONkmxEtr2smYXRC0tW2/2GU137RxdoiKhuqHEuZJbqmH7nlMfBXAM+3/XtJewFnAm8Hdgae5pZXYJT0RWBbyqimoa/ZbU9oknQ/a5eFfgRlpAvN8ca2Wx2AoDL9f9ehd52SNqasvNjZGjajqbEPfchPKbvlAGD7Tknvavu3NzxgsskGlPHJXa6R/ibgWT13ECdS/j26eEv4F+AXkr7PugtFtflDvvEYrz2ixbq97rB9bke1hkzpuQs/hPJL+xvAN5q5EG2bA8zuaGTJGra7Gq02mt5RLlDGwmeUSxtU1ireCnhE0+Uy1L+4GfDIjprRu4vNKspb4Fd1VBsGO072nOZPlxZLerPtdZY3kHQE5Y65CxdK+ijlXVHvg8k2t6CborXrj+9LeVc2pIuf7auBLYDfdlBr0hg2ykVklEurXgi8HphOCdahILuT8mS8dR7sLjYwwDsI2//ZjP/G9souagLvBL6lsrflUIDPoQxhPaijNgxtsTen51yrW9BRRnRcJOk2ykYil8Cah8StdXlJ+g7la3sUcK2ky1j3l9hL26o9Wdi+oulmmw0MZEb2SKrsQ5e0AXCY7S8PqP6jgeNYOyX6IuCDHfcr78LaO4iL276DUBl4fhxwdFNzA8q7k5Nsf7DN2j1t2AcY6ku/xnYXsyUHqhmTvSVlJNdQF9t2wKZtvTuQNOZmyLYvaqPuoKms7vgpyvj391A2rfl/lIfC7+5i7ZzxVBnoAJIutr3X+Fe2UvsblLejQ/+DX0fZKuvgluuOuXNNm6MeVNaPeRFwZDPufmiiyWcoI4v+b1u1JwtJB1KWbu3dgq6TX2aD1Izq2gu4yXZXXVyda2bBvpIy/v1CYEfby1V2yPrhZHgoWnOgv5fyNvRrrPtwrouhXGvGyY51roW6o41LHtokus0hdD8H9rN927Dz0yh3j62ODR40SfMpz2j2oUzBfwVlcbAjBtqwFjTDROc1yxtsCVwBLKGMeFlg+5ODbF9btO4OZOuMnupi/Hs/auxDHzK0CfTbes6ZbnaRuUfSnrYvhTVjlO9pu6jLLj2DsuHwMIfSj66yKl/tnmN7R5WtyD6gsi1cq1vADdBM21c3H78B+L7twyU9irJD1CcH1rJ2bSDpsZTuxNXNx0M3T5NiocNqA33A4XYUcEbTlw5lxuKIa1ZPJA1wbW7g3gf5Wi2GfmH/WWUP199Ttt+rUe/yuPvSbJ5i+0+SJs00+BY8mvLQfSjEe3+eJkVXR3WBLul5ti9opoA/gNvfOHcK8FqXTXM3a2re2WbNHh8f47W2R1zsJGmkr1OMPU68Ft9V2YLuI6wdaXPq4JrTqpslvZ0yumMX1i6V/Ag6XFW0a7ZnDLoN46ku0IHnUhbsGWm6t2nxbfDQmGBJz4ROg5ym3sCGS06CyR4DIWlXyvT745vjTYFfUPa2rPVB8BHAB4HnU3aj+mNz/tl0txF7jKDah6KDMLSORNN/OouyTnXvA9lO+lQlHT7S+bbX2Hg4GvT0+4heNd6hA2tWgXs5D1w4qIthZI+jrMX9PNaOOmn13cEwu/Z8vDGln/MKIIE+8QY9/T5ijWoDHTibMlvucnpmsbXsCSq7JF3NusMHocOHJrbf3nvcPJz9Ylf1H2YGPf0+BkDSnsAs26c3Q3M3HZp/MUg1f8NNt71/xzWnUHZLGmndlEH2bf2Z0gUUE28g0+8nAw1wI/ZBknQcZYmH7SnPDDak7FS1xyDbBXUH+k8kPd09+zx24LeTYWZgz1obUMbHzgbOGlyL6mX7w5J+yNrp973/7m8f/W9W4SR6VjQd41xtDqJsAn4FgO1bmjH4A1ddoDdrFZvytb1BZXusv7J2tmSbi9BPip2/gY/1fLwKuNH2pFlAqDa2fzbCuV8Noi1d0OTYiH2Q7rVtSYY1G1xMCtUFOvDiAdbed4C1hxbaPwp4KmXo3Oebvt2IiTQZNmIfpLMkfRZ4jKQ3U2alf26cv9OJaoctStoWWGH7r5L2BnYEzugZM1sdSV+jzOK7BDiAcmf+jrH/VsT6aybQfe3hOixT0n6UrS1F2Xbx+wNuElB3oC+lPLiYQdmoeCGwve0XDbBZrepdMEjSVMriULX3Z8aASLrAdpuzj2M91djlMmR1M2vzYOCTtk9qVgSs2Zo1NpqvfZBtifr9XGUP2YFMoOuapD+x7rySNS9Rns9tNpCG9ag50O+TdBhwOGuXAah2nYlG73oqomzDdyeT6BsuqtI7gW5IlxPoOmV7UoxkGUvNXS6zKQ8If2r7q5JmUtadOGHATYuIhzBJR9j+/LBzJ9ieN6g2rWlHrYHeS9IuLS8dG/GwI2k6Zdz5HpQ780uBd9Q+RFbSucCXhra4lPRpYGPbbxz7b7ZvUizKPpGah4HD1bqMacQgnU4ZbPAkYCvgOzw8Vls8GHi9pMMknUEZlz7wMIcK79CHVjwcdm5SbA8VUZNBbbU4KMP27H0U8G3KDk3vg262txxPjQ9FRxra8YHOWxFRv9skvZayng3AYZSHpLW6nHVHuQg4sPnT1faWY6rxDn0F8InRXrc96msR0T9J2wAnA7s3p35M6UO/cXCtenir8Q59rBUPI2KC2L4JeOmg2zEIkp7DA/daGPh+AzXeoT+gDz0iJp6kpwD/Qdl6zsBPgWNtLx9ow1om6YvAtsBS4P7mtG0fM7BGNWq8Q8+deUQ3vgKcQllOFuBQSn/6swbWom7MAWZ7Et4NVzdskQGveBjxMCLbX7S9qvnzJQa7kUtXrga2GHQjRlLdHfpkGDoU8TBxoaR5lI2xTdlT9Zyh4X0V/yxuDlwr6TJ6tre0PfDnCdX1oUdENySNtYembQ98GF8bJD13pPO2L+q6LcMl0CMi/gaS9gBebfttg25LjX3oEdEiSbtK2qLn+HBJZ0v61LDZlNWStLOkj0i6AfgQcN2AmwQk0CNi/X0WuBdA0l7ACcAZwB3AggG2q1WStpP0PknXUSZU3Uzp5djH9skDbh6QLpeIWE+SrrS9U/PxKcBK2+9vjmtey2U1ZXvHI2wva84tn0zPCnKHHhHra0rPqqb7Ahf0vFbdyLkeLwd+Rxnd8zlJ+zLJ5r0k0CNifX0VuEjS2cA9lLtWJD2V0u1SJdvfsn0IsAPwI+BY4ImSPiPpBQNtXCNdLhGx3iQ9G9gS+J7tu5tz2wGbPpw2k2keAr+SshvawDfMTqBHRFQiXS4REZVIoEdEVCKBHhFRiQR6REQlEugREZX4/ygyxUtzD2KEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FMNIST_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sport Shoes','Bag','Ankle Boots']\n",
    "plt.xticks(np.arange(10),labels=FMNIST_labels,rotation='vertical')\n",
    "plt.bar(np.arange(10), nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3bd9c191",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7gY5hARpOp4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21cd746afa0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def denormalize(tensor):\n",
    "  tensor = tensor*0.5 + 0.5\n",
    "  return tensor\n",
    "  \n",
    "img = img.view(28,-1)\n",
    "img = denormalize(img)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c83a438",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxTiil7cXOAz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4896e-06, 5.2015e-07, 8.4381e-06, 8.8204e-07, 5.9689e-06, 1.8997e-01,\n",
      "         4.8245e-06, 1.6213e-01, 4.4144e-03, 6.4347e-01],\n",
      "        [1.2188e-03, 4.6980e-05, 9.0725e-01, 1.9131e-04, 2.3490e-02, 1.1147e-05,\n",
      "         6.6653e-02, 9.7439e-09, 1.1407e-03, 5.0562e-07],\n",
      "        [1.1597e-05, 9.9983e-01, 2.9462e-05, 7.5223e-05, 5.5925e-05, 2.3330e-08,\n",
      "         1.2206e-07, 4.7394e-07, 4.6876e-09, 9.1409e-09],\n",
      "        [3.1499e-06, 9.9961e-01, 3.7330e-05, 3.0674e-04, 3.7486e-05, 1.6265e-07,\n",
      "         9.6245e-08, 1.9846e-06, 9.5102e-09, 5.5129e-08],\n",
      "        [1.1150e-01, 6.7287e-04, 1.8001e-01, 1.2703e-02, 1.5316e-02, 3.0327e-04,\n",
      "         6.6901e-01, 1.5421e-06, 1.0464e-02, 1.4989e-05],\n",
      "        [1.5485e-03, 9.8683e-01, 9.0868e-04, 1.9416e-03, 8.6741e-03, 5.6617e-07,\n",
      "         9.2075e-05, 4.4322e-06, 1.5532e-06, 2.6432e-07],\n",
      "        [1.0816e-02, 1.0569e-03, 5.5353e-02, 6.6553e-04, 7.9174e-01, 1.1839e-04,\n",
      "         1.3836e-01, 7.8579e-07, 1.8907e-03, 1.2058e-06],\n",
      "        [5.7395e-03, 3.8717e-04, 9.4565e-02, 2.3200e-03, 2.1569e-01, 5.0234e-04,\n",
      "         6.6566e-01, 7.3837e-07, 1.5122e-02, 7.1543e-06],\n",
      "        [1.0630e-02, 3.7859e-03, 2.3832e-02, 1.5216e-02, 6.4458e-03, 7.9903e-01,\n",
      "         1.2871e-02, 1.0110e-01, 2.5428e-02, 1.6554e-03],\n",
      "        [1.6509e-05, 1.2701e-05, 2.0509e-05, 3.9566e-05, 5.6326e-05, 3.1062e-02,\n",
      "         1.2708e-05, 9.6325e-01, 1.9697e-03, 3.5583e-03],\n",
      "        [6.5639e-04, 1.2965e-02, 3.4792e-01, 1.0108e-03, 5.8526e-01, 5.2740e-05,\n",
      "         5.1847e-02, 3.2058e-07, 2.9017e-04, 4.0901e-06],\n",
      "        [6.7707e-05, 3.4624e-05, 7.8345e-04, 3.9461e-05, 3.1758e-04, 8.4067e-01,\n",
      "         2.6071e-04, 7.8685e-02, 1.2095e-02, 6.7050e-02],\n",
      "        [2.3702e-04, 1.4964e-04, 2.6125e-03, 1.3236e-03, 1.7083e-03, 8.6590e-01,\n",
      "         7.3787e-04, 5.1466e-02, 7.4585e-02, 1.2783e-03],\n",
      "        [1.8572e-03, 4.5957e-03, 2.6110e-04, 9.9068e-01, 2.5190e-04, 5.7440e-06,\n",
      "         2.7939e-04, 1.3529e-03, 6.9251e-04, 2.8168e-05],\n",
      "        [3.7145e-04, 9.5195e-05, 1.9109e-02, 9.3908e-04, 9.0559e-01, 7.6517e-06,\n",
      "         6.2514e-02, 2.8226e-07, 1.1373e-02, 2.5890e-06],\n",
      "        [2.1652e-04, 9.8764e-01, 5.7423e-04, 1.0984e-02, 5.5767e-04, 9.2492e-07,\n",
      "         1.4753e-05, 1.1992e-05, 6.1782e-07, 5.6631e-07],\n",
      "        [7.3786e-02, 9.6779e-03, 7.3513e-01, 4.7323e-03, 3.1433e-02, 6.0889e-04,\n",
      "         1.4341e-01, 1.1462e-06, 1.2137e-03, 6.7057e-06],\n",
      "        [2.2943e-02, 2.1045e-04, 2.7524e-01, 2.0901e-03, 2.0073e-01, 6.3489e-05,\n",
      "         4.8173e-01, 3.3214e-07, 1.6993e-02, 5.3907e-06],\n",
      "        [3.1866e-04, 3.5975e-06, 2.2356e-03, 3.3732e-05, 1.6144e-03, 9.3892e-03,\n",
      "         1.7785e-03, 1.1030e-03, 9.8127e-01, 2.2568e-03],\n",
      "        [9.5169e-01, 5.4699e-05, 2.9019e-03, 3.5368e-03, 8.4162e-05, 1.0943e-07,\n",
      "         4.1669e-02, 6.3854e-09, 6.4375e-05, 1.3652e-08],\n",
      "        [3.9853e-01, 1.1858e-02, 2.4751e-01, 2.5114e-02, 3.5460e-02, 1.4478e-03,\n",
      "         2.5955e-01, 7.9038e-05, 1.9900e-02, 5.4686e-04],\n",
      "        [2.8323e-05, 7.1421e-05, 3.2529e-04, 1.3277e-04, 4.1156e-04, 5.3588e-01,\n",
      "         6.3157e-05, 4.4454e-01, 1.2199e-02, 6.3504e-03],\n",
      "        [7.8993e-08, 4.9712e-07, 9.1432e-07, 6.6984e-07, 2.4100e-06, 2.3683e-02,\n",
      "         1.0499e-07, 9.5587e-01, 6.5932e-04, 1.9780e-02],\n",
      "        [5.2290e-06, 4.1976e-06, 1.8948e-05, 6.4079e-06, 1.3724e-05, 4.0657e-01,\n",
      "         4.5997e-06, 5.0740e-01, 2.0265e-03, 8.3956e-02],\n",
      "        [3.4894e-06, 9.9971e-01, 2.0503e-05, 2.3542e-04, 2.9170e-05, 1.8700e-07,\n",
      "         5.9082e-08, 3.9932e-06, 1.0626e-08, 5.0958e-08],\n",
      "        [5.6065e-03, 2.7361e-03, 7.9556e-01, 1.0171e-02, 5.4617e-02, 3.9247e-03,\n",
      "         1.1748e-01, 4.1987e-06, 9.8952e-03, 1.1212e-05],\n",
      "        [1.1514e-03, 9.5453e-05, 9.1982e-02, 5.2067e-04, 4.1876e-01, 2.5440e-05,\n",
      "         4.8159e-01, 5.1839e-08, 5.8731e-03, 3.3734e-06],\n",
      "        [4.8957e-01, 1.7786e-02, 8.2291e-03, 4.2128e-01, 1.8711e-02, 3.5321e-07,\n",
      "         4.4005e-02, 3.9769e-06, 4.1471e-04, 5.8092e-07],\n",
      "        [3.0208e-07, 7.5979e-08, 1.0148e-06, 1.3382e-07, 9.8145e-07, 2.3284e-02,\n",
      "         5.7930e-07, 1.1645e-01, 2.5218e-03, 8.5774e-01],\n",
      "        [8.3629e-02, 1.5653e-03, 7.9520e-03, 2.5224e-01, 3.8097e-01, 2.3117e-06,\n",
      "         2.6035e-01, 1.1947e-05, 1.3274e-02, 3.3077e-06],\n",
      "        [3.3703e-06, 9.3588e-08, 7.1412e-05, 1.2475e-05, 3.3475e-04, 8.3508e-04,\n",
      "         1.0044e-04, 1.4869e-04, 9.9838e-01, 1.1431e-04],\n",
      "        [9.1374e-03, 1.3146e-05, 5.5398e-03, 1.7378e-02, 2.0468e-03, 8.2038e-04,\n",
      "         2.1557e-02, 4.4813e-05, 9.4343e-01, 3.7343e-05],\n",
      "        [1.3739e-02, 1.0495e-02, 7.2374e-03, 9.3441e-01, 7.5337e-03, 6.2808e-04,\n",
      "         1.1512e-02, 2.1155e-03, 1.2191e-02, 1.3616e-04],\n",
      "        [5.7981e-02, 4.9651e-04, 1.4674e-02, 8.7381e-01, 5.2577e-03, 8.0293e-07,\n",
      "         4.4153e-02, 4.2817e-06, 3.6175e-03, 5.5468e-07],\n",
      "        [2.0468e-04, 3.3164e-06, 6.0196e-03, 1.1808e-03, 9.2198e-04, 4.5997e-03,\n",
      "         2.3366e-03, 8.8039e-05, 9.8460e-01, 4.6803e-05],\n",
      "        [7.2453e-01, 4.0604e-04, 2.1892e-02, 2.3534e-02, 1.3754e-03, 4.3412e-05,\n",
      "         2.2650e-01, 1.3239e-06, 1.7126e-03, 1.3137e-06],\n",
      "        [3.9922e-06, 1.2361e-05, 6.2645e-06, 8.3773e-06, 2.8876e-05, 1.7016e-02,\n",
      "         2.8685e-06, 9.7704e-01, 4.7634e-04, 5.4036e-03],\n",
      "        [1.6042e-03, 3.0998e-04, 3.3989e-03, 1.4101e-03, 6.3110e-04, 9.5660e-01,\n",
      "         3.0515e-03, 2.6795e-02, 5.0988e-03, 1.1011e-03],\n",
      "        [2.0982e-06, 1.1295e-05, 1.1828e-05, 5.6239e-06, 5.0081e-05, 1.7174e-02,\n",
      "         2.2652e-06, 9.7656e-01, 8.5264e-04, 5.3259e-03],\n",
      "        [1.8680e-08, 3.5557e-09, 5.5629e-08, 4.0829e-09, 3.3515e-08, 2.4927e-03,\n",
      "         4.8930e-08, 7.5176e-03, 1.7906e-04, 9.8981e-01],\n",
      "        [6.5774e-01, 7.5881e-06, 1.7192e-03, 3.5766e-03, 9.3998e-04, 7.1394e-08,\n",
      "         3.3546e-01, 1.0214e-08, 5.5465e-04, 7.0170e-08],\n",
      "        [5.0628e-06, 9.9976e-01, 1.6894e-05, 1.4504e-04, 6.8761e-05, 3.6843e-08,\n",
      "         1.0843e-07, 5.9055e-06, 5.8470e-09, 1.1204e-07],\n",
      "        [2.0206e-01, 5.3193e-03, 5.5168e-02, 2.4090e-01, 2.0744e-01, 4.5368e-06,\n",
      "         2.8147e-01, 2.1133e-06, 7.6375e-03, 7.2545e-07],\n",
      "        [6.9153e-08, 2.7799e-08, 1.2891e-07, 1.2894e-08, 9.4012e-08, 1.7481e-02,\n",
      "         6.7503e-08, 1.4431e-01, 9.7904e-05, 8.3811e-01],\n",
      "        [3.5423e-03, 5.9813e-05, 1.1088e-01, 2.0089e-03, 2.2961e-01, 4.5782e-06,\n",
      "         6.5001e-01, 1.1985e-08, 3.8825e-03, 2.2151e-07],\n",
      "        [2.3699e-04, 3.2806e-05, 4.3570e-04, 9.0576e-05, 1.8726e-04, 6.7634e-01,\n",
      "         4.6166e-04, 2.0953e-01, 1.8732e-02, 9.3951e-02],\n",
      "        [2.9540e-02, 7.2744e-04, 7.3965e-01, 4.4454e-03, 2.2053e-02, 5.3753e-05,\n",
      "         2.0047e-01, 1.3836e-07, 3.0599e-03, 3.9858e-06],\n",
      "        [6.2641e-04, 9.5980e-01, 6.2587e-04, 3.7513e-02, 1.3373e-03, 5.0352e-07,\n",
      "         2.8877e-05, 6.3563e-05, 1.8581e-06, 1.6234e-06],\n",
      "        [1.4552e-03, 2.2667e-02, 5.6499e-01, 8.2439e-03, 3.6292e-01, 4.5352e-04,\n",
      "         3.7569e-02, 3.2091e-06, 1.6911e-03, 6.9169e-06],\n",
      "        [6.1810e-03, 1.2993e-04, 1.8973e-01, 2.3820e-03, 8.6602e-02, 5.9980e-05,\n",
      "         7.0599e-01, 9.0099e-08, 8.9288e-03, 2.7538e-06],\n",
      "        [1.2248e-02, 3.5722e-04, 2.3510e-01, 1.2178e-03, 4.1886e-01, 9.2542e-05,\n",
      "         3.1497e-01, 5.9526e-07, 1.7146e-02, 9.1289e-06],\n",
      "        [6.3755e-03, 7.8829e-04, 6.6347e-01, 2.3723e-03, 5.1077e-02, 2.0509e-03,\n",
      "         2.6877e-01, 7.1687e-07, 5.0838e-03, 3.4831e-06],\n",
      "        [2.9869e-03, 1.5427e-03, 7.3108e-03, 3.5527e-03, 1.1454e-03, 8.7476e-01,\n",
      "         3.3638e-03, 9.1175e-02, 6.9362e-03, 7.2218e-03],\n",
      "        [4.2006e-02, 1.1070e-04, 9.0130e-02, 2.0927e-03, 2.2631e-02, 3.1928e-03,\n",
      "         5.0007e-01, 1.3252e-05, 3.3857e-01, 1.1864e-03],\n",
      "        [1.0788e-02, 2.2661e-02, 5.6054e-01, 2.3949e-02, 3.2641e-01, 6.0798e-05,\n",
      "         5.3362e-02, 1.5481e-06, 2.2215e-03, 1.7662e-06],\n",
      "        [5.7830e-02, 1.3577e-03, 8.4272e-01, 2.4959e-03, 8.2619e-03, 1.3379e-04,\n",
      "         8.4650e-02, 3.2218e-07, 2.5373e-03, 8.4845e-06],\n",
      "        [1.9453e-04, 3.5004e-07, 6.0910e-04, 1.8540e-05, 2.0333e-03, 2.9705e-04,\n",
      "         1.2330e-03, 6.4505e-05, 9.9550e-01, 4.8318e-05],\n",
      "        [5.8754e-04, 2.9493e-04, 3.8207e-01, 1.3991e-03, 4.5676e-01, 4.7523e-05,\n",
      "         1.5357e-01, 1.5032e-07, 5.2676e-03, 1.8747e-06],\n",
      "        [1.5250e-04, 2.0206e-07, 5.4460e-04, 1.0213e-05, 7.5746e-04, 5.5300e-04,\n",
      "         1.0209e-03, 7.7202e-05, 9.9682e-01, 6.8739e-05],\n",
      "        [8.2143e-01, 8.7829e-03, 3.9413e-02, 2.0007e-02, 3.3559e-03, 1.7679e-04,\n",
      "         1.0616e-01, 1.1336e-05, 6.5750e-04, 8.4235e-06],\n",
      "        [1.5339e-06, 2.8225e-06, 3.8722e-06, 4.0023e-06, 8.3598e-06, 2.6272e-02,\n",
      "         1.1350e-06, 9.6907e-01, 3.2107e-04, 4.3185e-03],\n",
      "        [5.0088e-07, 9.0136e-07, 2.8406e-06, 2.2550e-06, 6.4518e-06, 5.8665e-02,\n",
      "         8.1219e-07, 8.8476e-01, 2.6128e-03, 5.3948e-02],\n",
      "        [7.6749e-07, 9.1655e-07, 1.2586e-04, 9.8104e-06, 7.2377e-04, 8.7551e-03,\n",
      "         2.2232e-05, 4.7291e-03, 9.8265e-01, 2.9782e-03],\n",
      "        [3.9319e-04, 6.4352e-05, 1.4044e-03, 2.0072e-04, 2.4252e-04, 9.7844e-01,\n",
      "         1.0329e-03, 9.7645e-03, 5.1627e-03, 3.2951e-03]])\n"
     ]
    }
   ],
   "source": [
    "# no need to calculate the gradients\n",
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    cnt = 0\n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps) # forward pass and the predictions are stored in logps\n",
    "        print(output)\n",
    "        cnt+=1\n",
    "        \n",
    "        if cnt > 0: # break after one pass\n",
    "          break\n",
    "        \n",
    "# each line is a probability that NN predicts the correct class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "06fc2244",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ij_wa7paveM"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #set_trace()\n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        \n",
    "        pred = torch.argmax(output, 1) # getting the value with the highest probability\n",
    "        total += labels.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bf3c334b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyxadgAyiRqg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 3, 7, 5, 8, 4, 5, 6, 8, 9, 1, 9, 1, 8, 1, 5]),\n",
       " tensor([3, 2, 7, 5, 8, 4, 5, 6, 8, 9, 1, 9, 1, 8, 1, 5]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b71cb7a0",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojLPwZLdi3OX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f364f440",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6V-3r9n-iCMb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 81.74% \n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #set_trace()\n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        \n",
    "        pred = torch.argmax(output, 1)\n",
    "        total += labels.size(0)\n",
    "        num_correct += (pred == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the 10000 test images: {num_correct * 100 / total}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6bfd6",
   "metadata": {
    "colab_type": "text",
    "id": "gXmCHcwKs6rd"
   },
   "source": [
    "# PyTorch playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4bba23e6",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzCCniVwNTdp"
   },
   "outputs": [],
   "source": [
    "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3e99c063",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fQLW-HL7_0pT",
    "outputId": "a2347d9a-bd38-4fa5-b11a-6c2ae5767134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "038ad1a6",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCJzXv0OK1Bs"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "mean, std = (0.5,), (0.5,)\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c9d3732e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqMqFbIVrbFH"
   },
   "outputs": [],
   "source": [
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 128)\n",
    "    self.fc2 = nn.Linear(128,64)\n",
    "    self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "model = FMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0e2faf94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "67eZUNEM5b7n",
    "outputId": "65d086ff-3a03-4cee-addd-315c55d7b626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMNIST(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7237bf",
   "metadata": {
    "colab_type": "text",
    "id": "XPdDu7KfWEfW"
   },
   "source": [
    "- The only change we have made to the code is that we are going to track the training loss, the testing loss and the accuracy across the 30 epochs.\n",
    "- We'll print out the train loss, the test loss and the accuracy after each epoch.\n",
    "- Because we are running this over 30 epochs this will take a bit longer to run - approx 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2a30b09a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "VJLzWi0UqGWm",
    "outputId": "77ce05a3-3f82-4cef-cefc-8a43c4ddbafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1/30) | Training loss: 1.0338174501843036 | Test loss: 0.6438944203079127 | Accuracy : 0.7646\n",
      "Epoch(2/30) | Training loss: 0.5607503942335084 | Test loss: 0.5492629501849983 | Accuracy : 0.8019\n",
      "Epoch(3/30) | Training loss: 0.491598510475301 | Test loss: 0.5054487923907626 | Accuracy : 0.8153\n",
      "Epoch(4/30) | Training loss: 0.45538549036232395 | Test loss: 0.4784524805226903 | Accuracy : 0.8272\n",
      "Epoch(5/30) | Training loss: 0.43235718722600164 | Test loss: 0.4571964134266422 | Accuracy : 0.834\n",
      "Epoch(6/30) | Training loss: 0.41507624634611073 | Test loss: 0.4552511823405126 | Accuracy : 0.8364\n",
      "Epoch(7/30) | Training loss: 0.40099091047861934 | Test loss: 0.43269140439428344 | Accuracy : 0.844\n",
      "Epoch(8/30) | Training loss: 0.388984460915838 | Test loss: 0.4238618138679274 | Accuracy : 0.8462\n",
      "Epoch(9/30) | Training loss: 0.3774063554145634 | Test loss: 0.42526366224714146 | Accuracy : 0.8494\n",
      "Epoch(10/30) | Training loss: 0.36864431833089795 | Test loss: 0.40582276111955096 | Accuracy : 0.8543\n",
      "Epoch(11/30) | Training loss: 0.36095893352842534 | Test loss: 0.40125934124752216 | Accuracy : 0.8544\n",
      "Epoch(12/30) | Training loss: 0.35247999976978883 | Test loss: 0.40307781745673743 | Accuracy : 0.8564\n",
      "Epoch(13/30) | Training loss: 0.345308247898052 | Test loss: 0.39089980294370347 | Accuracy : 0.8601\n",
      "Epoch(14/30) | Training loss: 0.33897137986635095 | Test loss: 0.38924433357396704 | Accuracy : 0.8573\n",
      "Epoch(15/30) | Training loss: 0.33263765888681796 | Test loss: 0.4027740325138068 | Accuracy : 0.8555\n",
      "Epoch(16/30) | Training loss: 0.32657915681822974 | Test loss: 0.3839665171067426 | Accuracy : 0.8634\n",
      "Epoch(17/30) | Training loss: 0.3212923827662524 | Test loss: 0.3746717103347657 | Accuracy : 0.8675\n",
      "Epoch(18/30) | Training loss: 0.3164205460993847 | Test loss: 0.37683959618495527 | Accuracy : 0.8615\n",
      "Epoch(19/30) | Training loss: 0.31207336221676646 | Test loss: 0.37541891805305605 | Accuracy : 0.8646\n",
      "Epoch(20/30) | Training loss: 0.3063709022743361 | Test loss: 0.3681151199682503 | Accuracy : 0.8714\n",
      "Epoch(21/30) | Training loss: 0.30189204746599135 | Test loss: 0.3659730233774064 | Accuracy : 0.8703\n",
      "Epoch(22/30) | Training loss: 0.29723321906189676 | Test loss: 0.36075284820833026 | Accuracy : 0.8717\n",
      "Epoch(23/30) | Training loss: 0.2932342765157792 | Test loss: 0.36484445280330197 | Accuracy : 0.8712\n",
      "Epoch(24/30) | Training loss: 0.2885124905944379 | Test loss: 0.3734624371596962 | Accuracy : 0.8655\n",
      "Epoch(25/30) | Training loss: 0.28413750749947164 | Test loss: 0.3529488008682895 | Accuracy : 0.8726\n",
      "Epoch(26/30) | Training loss: 0.2810416592082489 | Test loss: 0.3473573356487189 | Accuracy : 0.8773\n",
      "Epoch(27/30) | Training loss: 0.2766368763326709 | Test loss: 0.3634589965556078 | Accuracy : 0.8713\n",
      "Epoch(28/30) | Training loss: 0.27274943593500267 | Test loss: 0.34798906582176303 | Accuracy : 0.8748\n",
      "Epoch(29/30) | Training loss: 0.2695006458108613 | Test loss: 0.37235231365367866 | Accuracy : 0.8714\n",
      "Epoch(30/30) | Training loss: 0.2657932349200696 | Test loss: 0.36358268093910945 | Accuracy : 0.8691\n",
      "\n",
      "Number correct : 8691, Total : 10000\n",
      "Accuracy of the model after 30 epochs on the 10000 test images: 86.91% \n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 30\n",
    "train_tracker, test_tracker, accuracy_tracker = [], [], []\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "    \n",
    "    for batch, (images, labels) in enumerate(trainloader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "    \n",
    "    train_tracker.append(cum_loss/len(trainloader))\n",
    "    print(f\"Epoch({i+1}/{num_epochs}) | Training loss: {cum_loss/len(trainloader)} | \",end='')\n",
    "    \n",
    "    test_loss = 0\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch, (images, labels) in enumerate(testloader,1):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        logps = model(images)\n",
    "        batch_loss = criterion(logps, labels)        \n",
    "        test_loss += batch_loss.item()\n",
    "        \n",
    "        output = torch.exp(logps)\n",
    "        pred = torch.argmax(output, 1)\n",
    "        total += labels.size(0)\n",
    "        num_correct += (pred == labels).sum().item()\n",
    "    \n",
    "    test_tracker.append(test_loss/len(testloader))\n",
    "    print(f\"Test loss: {test_loss/len(testloader)} | \", end='')\n",
    "    accuracy_tracker.append(num_correct/total)\n",
    "    print(f'Accuracy : {num_correct/total}')        \n",
    "print(f'\\nNumber correct : {num_correct}, Total : {total}')\n",
    "print(f'Accuracy of the model after 30 epochs on the 10000 test images: {num_correct * 100 / total}% ')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5ae51",
   "metadata": {
    "colab_type": "text",
    "id": "IqNpkYO6V9YI"
   },
   "source": [
    "- Has the accuracy of the model increased? YES\n",
    "- Now plot the training loss vs the test loss over 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a577d2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "89a8FdTi-cNM",
    "outputId": "82701451-7413-4c00-d4e7-24f0e375a4c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f00c8cb33c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nabgrpVQE0nBXSqkIpOGulFIR6P8D3J8T5j30lfkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_tracker, label='Training loss')\n",
    "plt.plot(test_tracker, label='Test loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d82566",
   "metadata": {
    "colab_type": "text",
    "id": "DHtKTHKKjG3r"
   },
   "source": [
    "- Now add the accuracy to the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6972a79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "AJgyMHm2Pvx5",
    "outputId": "881d9ce0-19cd-4991-86a1-2d014ee00735"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f00c8da8f98>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF0KIMCThLoQQYUjCXQghwtD/BxdsaWtscTIRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_tracker, label='Training loss')\n",
    "plt.plot(test_tracker, label='Test loss')\n",
    "plt.plot(accuracy_tracker, label='Test accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53278ad1",
   "metadata": {
    "colab_type": "text",
    "id": "APhVglVTk-og"
   },
   "source": [
    "## Further challenges and experiments \n",
    "*if I have spare time cause oh god it takes ages to train more complex things...*\n",
    "- Can you get better accuracy from a model if you :\n",
    "    - Add more layers? \n",
    "    - Change the number of nodes in the layers?\n",
    "    - Train over fewer/higher epochs?\n",
    "    \n",
    "- Can you improve on your results if you add additional layers like [Dropout](https://pytorch.org/docs/master/nn.html#torch.nn.Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfca58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
